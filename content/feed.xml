<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.4.3">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-04-02T20:29:54+08:00</updated><id>/</id><title type="html">Apache ServiceComb (incubating)</title><subtitle>The homepage of ServiceComb</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;&quot;/assets/images/ServiceComb-logo-3.jpg&quot;, &quot;bio&quot;=&gt;&quot;ServiceComb is a microservice framework that provides service registration, discovery, configuration and management utilities.&quot;, &quot;biocn&quot;=&gt;&quot;ServiceComb提供了一套关于服务注册，服务发现，服务配置以及管理功能的微服务框架&quot;, &quot;location&quot;=&gt;&quot;China&quot;, &quot;locationcn&quot;=&gt;&quot;中国&quot;, &quot;email&quot;=&gt;&quot;servicecomb-developers@googlegroups.com&quot;, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;&quot;ServiceComb&quot;, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil}</name><email>servicecomb-developers@googlegroups.com</email></author><entry xml:lang="en"><title type="html">Howto Upgrade to Zipkin2</title><link href="/docs/howto-upgrade-topzipkin2/" rel="alternate" type="text/html" title="Howto Upgrade to Zipkin2" /><published>2018-01-10T00:00:00+08:00</published><updated>2018-01-11T10:26:28+08:00</updated><id>/docs/howto-upgrade-to-zipkin-v2</id><content type="html" xml:base="/docs/howto-upgrade-topzipkin2/">&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Java Chassis uses zipkin as the default tracing implementation.&lt;/p&gt;

&lt;p&gt;Zipkin introduced &lt;a href=&quot;http://zipkin.io/zipkin-api/#/&quot;&gt;v2 http api&lt;/a&gt; in version 1.31 which simplifies data types. There are also various other improvements and new features added to the zipkin libraries, so it seems a good time for us to follow the upstream and upgrade to zipkin2.&lt;/p&gt;

&lt;h3 id=&quot;version-matrix&quot;&gt;Version matrix&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;module&lt;/th&gt;
      &lt;th&gt;current&lt;/th&gt;
      &lt;th&gt;target&lt;/th&gt;
      &lt;th&gt;supports v2 since&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;zipkin&lt;/td&gt;
      &lt;td&gt;1.24.0&lt;/td&gt;
      &lt;td&gt;2.4.2&lt;/td&gt;
      &lt;td&gt;2.0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;brave&lt;/td&gt;
      &lt;td&gt;4.13.1&lt;/td&gt;
      &lt;td&gt;4.13.1&lt;/td&gt;
      &lt;td&gt;4.7.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;reporter&lt;/td&gt;
      &lt;td&gt;0.10.0&lt;/td&gt;
      &lt;td&gt;2.2.2&lt;/td&gt;
      &lt;td&gt;2.0.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;whats-changed&quot;&gt;What’s changed&lt;/h2&gt;

&lt;p&gt;Zipkin did a very good job on maintaining backward compatibility. All the changes that breaks compatiblity are packaged into a new group(&lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.java&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.zipkin2&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.reporter&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.reporter2&lt;/code&gt;). And v1/v2 libraries can coexist.&lt;/p&gt;

&lt;p&gt;The zipkin2 library can use both v1 and v2 api to communicate with server.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;zipkin2.Span&lt;/code&gt; class changed a bit from the old &lt;code class=&quot;highlighter-rouge&quot;&gt;zipkin.Span&lt;/code&gt; class. The public fields are refactored to methods. And the &lt;code class=&quot;highlighter-rouge&quot;&gt;BinaryAnnotation&lt;/code&gt; class is removed along with &lt;code class=&quot;highlighter-rouge&quot;&gt;zipkin.Span.binaryAnnotaions&lt;/code&gt; field. It’s functionality is replaced by &lt;code class=&quot;highlighter-rouge&quot;&gt;zipkin2.Span.tags()&lt;/code&gt; method which return a &lt;code class=&quot;highlighter-rouge&quot;&gt;Map&amp;lt;String,String&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;upgrade-to-zipkin2-for-java-chassis&quot;&gt;Upgrade to zipkin2 for Java Chassis&lt;/h2&gt;

&lt;h3 id=&quot;modify-the-maven-dependencies-to-use-the-target-version-of-related-libraries&quot;&gt;Modify the maven dependencies to use the target version of related libraries.&lt;/h3&gt;
&lt;p&gt;Change the group &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.java&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.reporter&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.zipkin2&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;io.zipkin.reporter2&lt;/code&gt; respectively.&lt;/p&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java-chassis-dependencies/pom.xml
&lt;span class=&quot;gu&quot;&gt;@@ -50,8 +50,8 @@
&lt;/span&gt;     &amp;lt;cxf.version&amp;gt;3.1.6&amp;lt;/cxf.version&amp;gt;
     &amp;lt;logback.version&amp;gt;1.1.7&amp;lt;/logback.version&amp;gt;
     &amp;lt;brave.version&amp;gt;4.13.1&amp;lt;/brave.version&amp;gt;
&lt;span class=&quot;gd&quot;&gt;-    &amp;lt;zipkin.version&amp;gt;1.24.0&amp;lt;/zipkin.version&amp;gt;
-    &amp;lt;zipkin-reporter.version&amp;gt;0.10.0&amp;lt;/zipkin-reporter.version&amp;gt;
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+    &amp;lt;zipkin.version&amp;gt;2.4.2&amp;lt;/zipkin.version&amp;gt;
+    &amp;lt;zipkin-reporter.version&amp;gt;2.2.2&amp;lt;/zipkin-reporter.version&amp;gt;
&lt;/span&gt;   &amp;lt;/properties&amp;gt;
 
   &amp;lt;dependencyManagement&amp;gt;
&lt;span class=&quot;gu&quot;&gt;@@ -646,7 +646,7 @@
&lt;/span&gt; 
       &amp;lt;!-- zipkin dependencies --&amp;gt;
       &amp;lt;dependency&amp;gt;
&lt;span class=&quot;gd&quot;&gt;-        &amp;lt;groupId&amp;gt;io.zipkin.java&amp;lt;/groupId&amp;gt;
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+        &amp;lt;groupId&amp;gt;io.zipkin.zipkin2&amp;lt;/groupId&amp;gt;
&lt;/span&gt;         &amp;lt;artifactId&amp;gt;zipkin&amp;lt;/artifactId&amp;gt;
         &amp;lt;version&amp;gt;${zipkin.version}&amp;lt;/version&amp;gt;
       &amp;lt;/dependency&amp;gt;
&lt;span class=&quot;gu&quot;&gt;@@ -661,7 +661,7 @@
&lt;/span&gt;         &amp;lt;version&amp;gt;${brave.version}&amp;lt;/version&amp;gt;
       &amp;lt;/dependency&amp;gt;
       &amp;lt;dependency&amp;gt;
&lt;span class=&quot;gd&quot;&gt;-        &amp;lt;groupId&amp;gt;io.zipkin.reporter&amp;lt;/groupId&amp;gt;
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+        &amp;lt;groupId&amp;gt;io.zipkin.reporter2&amp;lt;/groupId&amp;gt;
&lt;/span&gt;         &amp;lt;artifactId&amp;gt;zipkin-sender-okhttp3&amp;lt;/artifactId&amp;gt;
         &amp;lt;version&amp;gt;${zipkin-reporter.version}&amp;lt;/version&amp;gt;
       &amp;lt;/dependency&amp;gt;

handlers/handler-tracing-zipkin/pom.xml
&lt;span class=&quot;gu&quot;&gt;@@ -50,7 +50,7 @@
&lt;/span&gt;       &amp;lt;artifactId&amp;gt;brave&amp;lt;/artifactId&amp;gt;
     &amp;lt;/dependency&amp;gt;
     &amp;lt;dependency&amp;gt;
&lt;span class=&quot;gd&quot;&gt;-      &amp;lt;groupId&amp;gt;io.zipkin.reporter&amp;lt;/groupId&amp;gt;
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+      &amp;lt;groupId&amp;gt;io.zipkin.reporter2&amp;lt;/groupId&amp;gt;
&lt;/span&gt;       &amp;lt;artifactId&amp;gt;zipkin-sender-okhttp3&amp;lt;/artifactId&amp;gt;
     &amp;lt;/dependency&amp;gt;
     &amp;lt;dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;make-brave-to-use-zipkin2-instead-of-zipkin&quot;&gt;Make brave to use zipkin2 instead of zipkin&lt;/h3&gt;

&lt;p&gt;Change the zipkin.xxx import to zipkin2.xxx on imports, and most importantly, use &lt;code class=&quot;highlighter-rouge&quot;&gt;spanReporter()&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;reporter()&lt;/code&gt; for generating reporter for brave, change the api path to /api/v2/xxx when creating sender.&lt;/p&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;handlers/handler-tracing-zipkin/src/main/java/io/servicecomb/tracing/zipkin/TracingConfiguration.java
&lt;span class=&quot;gu&quot;&gt;@@ -31,11 +31,11 @@
&lt;/span&gt; import brave.http.HttpTracing;
 import brave.propagation.CurrentTraceContext;
 import io.servicecomb.config.DynamicProperties;
&lt;span class=&quot;gd&quot;&gt;-import zipkin.Span;
-import zipkin.reporter.AsyncReporter;
-import zipkin.reporter.Reporter;
-import zipkin.reporter.Sender;
-import zipkin.reporter.okhttp3.OkHttpSender;
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+import zipkin2.Span;
+import zipkin2.reporter.AsyncReporter;
+import zipkin2.reporter.Reporter;
+import zipkin2.reporter.Sender;
+import zipkin2.reporter.okhttp3.OkHttpSender;
&lt;/span&gt; 
 @Configuration
 class TracingConfiguration {
&lt;span class=&quot;gu&quot;&gt;@@ -56,14 +56,15 @@ Sender sender(DynamicProperties dynamicProperties) {
&lt;/span&gt;     return AsyncReporter.builder(sender).build();
   }
 
&lt;span class=&quot;gi&quot;&gt;+
&lt;/span&gt;   @Bean
   Tracing tracing(Reporter&amp;lt;Span&amp;gt; reporter, DynamicProperties dynamicProperties,
       CurrentTraceContext currentTraceContext) {
     return Tracing.newBuilder()
         .localServiceName(dynamicProperties.getStringProperty(CONFIG_QUALIFIED_MICROSERVICE_NAME_KEY,
             DEFAULT_MICROSERVICE_NAME))
         .currentTraceContext(currentTraceContext) // puts trace IDs into logs
&lt;span class=&quot;gd&quot;&gt;-        .reporter(reporter)
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+        .spanReporter(reporter)
&lt;/span&gt;         .build();
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;https://github.com/openzipkin/brave/releases/tag/4.7.1&quot;&gt;brave release notes&lt;/a&gt;, it’s stated that we need to use &lt;code class=&quot;highlighter-rouge&quot;&gt;create()&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;builder()&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
   /** Configuration for how to buffer spans into messages for Zipkin */
&lt;span class=&quot;gd&quot;&gt;-  @Bean Reporter&amp;lt;Span&amp;gt; reporter() {
-    return AsyncReporter.builder(sender()).build();
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+  @Bean Reporter&amp;lt;Span&amp;gt; spanReporter() {
+    return AsyncReporter.create(sender()).build();
&lt;/span&gt;   }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;But this will not work. In &lt;code class=&quot;highlighter-rouge&quot;&gt;zipkin2.Reporter&lt;/code&gt;, the &lt;code class=&quot;highlighter-rouge&quot;&gt;create(sender)&lt;/code&gt; is actually equivalent to &lt;code class=&quot;highlighter-rouge&quot;&gt;builder(sender).build()&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncReporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Span&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sender&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncReporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncReporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Builder&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sender&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncReporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;make-changes-according-to-the-changes-of-zipkinspan-and-zipkin2span&quot;&gt;Make changes according to the changes of zipkin.Span and zipkin2.Span.&lt;/h3&gt;

&lt;p&gt;We do not use zipkin.Span in our production code, but we do use it in our tests. Those changes are quite straight forward, we just change the accessing of fields to calling methods as described in the What’s Changed section.&lt;/p&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tracing/tracing-zipkin/src/test/java/io/servicecomb/tracing/zipkin/ZipkinSpanAspectTest.java 
&lt;span class=&quot;gu&quot;&gt;@@ -45,7 +45,7 @@
&lt;/span&gt; import io.servicecomb.tracing.zipkin.app.ZipkinSpanTestApplication;
 import io.servicecomb.tracing.zipkin.app.ZipkinSpanTestApplication.CustomSpanTask;
 import io.servicecomb.tracing.zipkin.app.ZipkinSpanTestApplication.SomeSlowTask;
&lt;span class=&quot;gd&quot;&gt;-import zipkin.Span;
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+import zipkin2.Span;
&lt;/span&gt; 
 @RunWith(SpringRunner.class)
 @SpringBootTest(classes = {ZipkinSpanTestApplication.class, TracingConfig.class})
&lt;span class=&quot;gu&quot;&gt;@@ -74,8 +74,8 @@ public void reportedSpanContainsAnnotatedMethodInfo() throws Exception {
&lt;/span&gt; 
     await().atMost(2, SECONDS).until(() -&amp;gt; !spans.isEmpty());
 
&lt;span class=&quot;gd&quot;&gt;-    zipkin.Span span = spans.poll();
-    assertThat(span.name, is(&quot;crawl&quot;));
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+    zipkin2.Span span = spans.poll();
+    assertThat(span.name(), is(&quot;crawl&quot;));
&lt;/span&gt;     assertThat(tracedValues(span), contains(SomeSlowTask.class.getMethod(&quot;crawl&quot;).toString()));
   }
   
&lt;span class=&quot;gu&quot;&gt;@@ -84,17 +84,17 @@ public void reportCustomSpanInfomation() throws Exception {
&lt;/span&gt;     customSpanTask.invoke();
     await().atMost(2, SECONDS).until(() -&amp;gt; !spans.isEmpty());
   
&lt;span class=&quot;gd&quot;&gt;-    zipkin.Span span = spans.poll();
-    assertThat(span.name, is(&quot;transaction1&quot;));
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+    zipkin2.Span span = spans.poll();
+    assertThat(span.name(), is(&quot;transaction1&quot;));
&lt;/span&gt;     assertThat(tracedValues(span), contains(&quot;startA&quot;));
     
   }
 
&lt;span class=&quot;gd&quot;&gt;-  private List&amp;lt;String&amp;gt; tracedValues(zipkin.Span spans) {
-    return spans.binaryAnnotations.stream()
-        .filter(span -&amp;gt; CALL_PATH.equals(span.key) || &quot;error&quot;.equals(span.key))
-        .filter(span -&amp;gt; span.value != null)
-        .map(annotation -&amp;gt; new String(annotation.value))
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+  private List&amp;lt;String&amp;gt; tracedValues(zipkin2.Span spans) {
+    return spans.tags().entrySet().stream()
+        .filter(span -&amp;gt; CALL_PATH.equals(span.getKey()) || &quot;error&quot;.equals(span.getKey()))
+        .filter(span -&amp;gt; span.getValue() != null)
+        .map(annotation -&amp;gt; new String(annotation.getValue()))
&lt;/span&gt;         .distinct()
         .collect(Collectors.toList());
   }
&lt;span class=&quot;gu&quot;&gt;@@ -110,7 +110,7 @@ public void reportCustomSpanInfomation() throws Exception {
&lt;/span&gt;     Tracing tracing(Queue&amp;lt;Span&amp;gt; spans) {
       return Tracing.newBuilder()
           .currentTraceContext(new StrictCurrentTraceContext())
&lt;span class=&quot;gd&quot;&gt;-          .reporter(spans::add)
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+          .spanReporter(spans::add)
&lt;/span&gt;           .build();
     }
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;support-both-v1-and-v2-api-of-zipkin-server&quot;&gt;Support both v1 and v2 api of zipkin server.&lt;/h3&gt;

&lt;p&gt;Our customers may be still running a zipkin server prior to 1.31 which does not support the v2 http api. So we added an option to let them specify the server api version.&lt;/p&gt;

&lt;p&gt;Supporting v1 api is built into zipkin2, so we do not need to rely on the v1 libraries. Just use the &lt;code class=&quot;highlighter-rouge&quot;&gt;SpanBytesEncoder.JSON_V1&lt;/code&gt; when building reporter and change the sender api path.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;URLConnectionSender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://localhost:9411/api/v1/spans&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reporter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AsyncReporter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sender&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SpanBytesEncoder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;JSON_V1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That’s all, for the complete changes, please refer the &lt;a href=&quot;https://github.com/apache/incubator-servicecomb-java-chassis/pull/488&quot;&gt;pull request&lt;/a&gt; for the complete changes.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/openzipkin/zipkin/releases/tag/2.0.0&quot;&gt;Zipkin 2.0.0 release notes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/openzipkin/brave/releases/tag/4.7.1&quot;&gt;Brave 4.7.1 release notes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/openzipkin/brave/tree/master/brave&quot;&gt;Brave API V4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yang Bo</name><email>yangbo12@huawei.com</email></author><category term="zipkin" /><summary type="html">Changes between v1 and v2 of zipkin and how Java Chassis upgraded to zipkin2</summary></entry><entry xml:lang="en"><title type="html">Proposal for refactoring service registry module in Java Chassis</title><link href="/docs/service-registry-refactor-proposal/" rel="alternate" type="text/html" title="Proposal for refactoring service registry module in Java Chassis" /><published>2017-12-19T00:00:00+08:00</published><updated>2017-12-19T09:18:43+08:00</updated><id>/docs/service-registry-refactor-proposal</id><content type="html" xml:base="/docs/service-registry-refactor-proposal/">&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;The architecture of the &lt;code class=&quot;highlighter-rouge&quot;&gt;service registry&lt;/code&gt; module in Java Chassis is as follows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/service_registry.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, it has the following problems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Low level components access high level components frequently. The cyclic relationships make the implementation complicated and introduce some redundant access points.&lt;/li&gt;
  &lt;li&gt;Low level components should be stateless to be reused by high level components. Introducing state into low level components makes it relies heavily on the high level components, causing cyclic relationships.&lt;/li&gt;
  &lt;li&gt;Hard to integrate with third-party framework. It does not provide a standalone client with cache capability inside. It also requires the configurations should be loaded from dynamic properties.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;proposed-architecture&quot;&gt;Proposed Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/proposed_architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above architecture is what the &lt;code class=&quot;highlighter-rouge&quot;&gt;service registry&lt;/code&gt; module supposed to be in my opinion. The low level components like &lt;code class=&quot;highlighter-rouge&quot;&gt;ApiManager&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;UriManager&lt;/code&gt; are stateless so they do not rely on high level components any more. Relationships between components are clear and simple.&lt;/p&gt;

&lt;p&gt;Tasks can be divided into the following parts:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/task.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are two types of tasks:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Simple Task. Task that executes only once.&lt;/li&gt;
  &lt;li&gt;Period Task. Task that executes at every interval.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The result of task will convert to event and posts to the &lt;code class=&quot;highlighter-rouge&quot;&gt;EventManager&lt;/code&gt;. Any methods that subscribes that kind of event will be notified and execute the corresponding response, e.g. update the cache.&lt;/p&gt;

&lt;p&gt;Both the outside requests and chassis requests share the same interface of Configuration, they can implement their own way to load configurations. The difference between chassis requests and outside requests is that chassis requests need to manage microservice informations of their own. Besides,  chassis requests also need to provide a compatible interface for requests to use. There comes  to the component &lt;code class=&quot;highlighter-rouge&quot;&gt;RegistryUtils&lt;/code&gt;. It is responsible for the following stuff:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Initialize service registry client with configurations.&lt;/li&gt;
  &lt;li&gt;Initialization of service center service, attach with a PullTask.&lt;/li&gt;
  &lt;li&gt;Initialization of service itself, attach with RegisterTask, HeartbeatTask and WatchTask.&lt;/li&gt;
  &lt;li&gt;Provide wrapper method for service registry client.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The initialization process of service registry client is as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/client_initialization.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If the auto discovery switch is on, it need to create a period task &lt;code class=&quot;highlighter-rouge&quot;&gt;PullTask&lt;/code&gt; to make the available service center services’ information up to date.&lt;/p&gt;

&lt;p&gt;Any requests to a new microservice will create a new entry in the service registry client. Once we access the same microservice again, the client will response with the cached version which reduces communication cost with service center.&lt;/p&gt;

&lt;p&gt;Let’s checkout how the &lt;code class=&quot;highlighter-rouge&quot;&gt;Microservice&lt;/code&gt; component works. Instances and its versions are cached inside the microservice. To get an instance of a specified id, all it needs to do is lookup the cache or create a query task to update the cache. All interactions from &lt;code class=&quot;highlighter-rouge&quot;&gt;Microservice&lt;/code&gt; to  &lt;code class=&quot;highlighter-rouge&quot;&gt;ApiManager&lt;/code&gt; are done by the &lt;code class=&quot;highlighter-rouge&quot;&gt;Task&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;ApiManager&lt;/code&gt; is designed to interact directly with service center as a pure client with api inside only. Its structure is as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/api_manager.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Eric Lee</name><email>eric.lee.ltk@gmail.com</email><uri>https://eric-lee-ltk.github.io</uri></author><category term="refactor" /><summary type="html">Analysis of service registry and propose a new architecture for it</summary></entry><entry xml:lang="cn"><title type="html">老司机带你刷任务 - ServiceComb JIRA入门指南</title><link href="/cn/docs/jira_beginner_guide/" rel="alternate" type="text/html" title="老司机带你刷任务 - ServiceComb JIRA入门指南" /><published>2017-11-16T00:00:00+08:00</published><updated>2017-11-16T11:43:00+08:00</updated><id>/cn/docs/jira-beginner-guide</id><content type="html" xml:base="/cn/docs/jira_beginner_guide/">&lt;p&gt;想参与社区贡献，却感觉老虎咬天，无从下口？不用担心，老司机带你一起刷新手任务！&lt;/p&gt;

&lt;p&gt;ServiceComb的所有任务托管在&lt;a href=&quot;https://servicecomb.atlassian.net&quot;&gt;ServiceComb JIRA&lt;/a&gt;上，
首先你需要&lt;a href=&quot;https://id.atlassian.com/signup?continue=https%3A%2F%2Fservicecomb.atlassian.net%2Flogin%3FredirectCount%3D1&quot;&gt;注册&lt;/a&gt;一个免费JIRA账户。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.signup.png&quot; alt=&quot;jira sign up&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;登陆后请首先花几分钟上传自己的个性头像，让大家可以一眼看出哪些任务在你的掌控之下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.board.profile.png&quot; alt=&quot;jira profile&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来在菜单栏点击Boards，选择ServiceComb转到如下Kanban board。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.board.selection.png&quot; alt=&quot;jira board selection&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ServiceComb Kanban board页面分为三列：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;To Do：还未开始的任务&lt;/li&gt;
  &lt;li&gt;In Progress：进行中的任务&lt;/li&gt;
  &lt;li&gt;Done：已完成的任务&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.board.png&quot; alt=&quot;jira board&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To Do列的任务卡上如果没有头像，代表这个任务无人领取，但作为新手，我怎么知道哪个任务容易上手呢？
我们很细心的为新手任务加上了绿色竖线标记，这个标记对应所有打了 &lt;code class=&quot;highlighter-rouge&quot;&gt;good-first-issue&lt;/code&gt; 标签的任务，
以便大家一眼识别，立即上手。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.good.first.issue.png&quot; alt=&quot;jira good first issue&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.story.png&quot; alt=&quot;jira story&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;另外，任务还按照功能模块划分了epic，这样大家可以在自己擅长的领域大显身手，或者在全新的模块挑战自己。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.epic.png&quot; alt=&quot;jira epic&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;选到心仪的任务后，记得讲任务分配给自己，以免被别人抢走。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.story.assignment.png&quot; alt=&quot;jira story assignment&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;另外别忘了根据自己的进度，更新对应任务的状态，你可以直接拖动任务卡到对应状态列。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.status.update.png&quot; alt=&quot;jira status update&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后，在完成任务后，咨询项目带队老司机，将自己的贡献添加到对应的发布版本中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/jira/jira.fix.version.png&quot; alt=&quot;jira fix.version&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看到现在相信你已经跃跃欲试，赶紧加入我们一起刷任务升级吧！&lt;/p&gt;</content><author><name>Sean Yin</name><email>seanyinx@gmail.com</email><uri>http://seanyinx.github.io</uri></author><summary type="html">ServiceComb JIRA入门指南</summary></entry><entry xml:lang="cn"><title type="html">Service-Center Management UI Console</title><link href="/docs/service-center-ui/" rel="alternate" type="text/html" title="Service-Center Management UI Console" /><published>2017-10-28T00:00:00+08:00</published><updated>2017-10-30T09:18:43+08:00</updated><id>/docs/service-center-ui</id><content type="html" xml:base="/docs/service-center-ui/">&lt;p&gt;Service-Center Management UI Console enables user to view the list of MicroServices registered in SC.
Users can view the detailed information of their MicroServices, Instances and Schemas.
Service-Center UI also offers a unique feature of testing the Schemas of their MicroServices from UI, Users 
can also download the html client for their Schemas.&lt;/p&gt;

&lt;h3 id=&quot;preview-of-management-console&quot;&gt;Preview of Management Console&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/Service-Center-UI-Preview.gif&quot; alt=&quot;Preview&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;features&quot;&gt;Features&lt;/h3&gt;
&lt;p&gt;Service-Center Management console offers very useful features which makes users easy to use and manage service-center.&lt;/p&gt;

&lt;h3 id=&quot;dashboard&quot;&gt;Dashboard&lt;/h3&gt;
&lt;p&gt;This is the place where you can get the overall information about the services which are registered in your service-center like total number of services, providers, consumers and total instances. You can also get a list of Services which based on their current status.&lt;br /&gt;
&lt;img src=&quot;/assets/images/Dashboard.PNG&quot; alt=&quot;Dashboard&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;micro-service-list&quot;&gt;Micro-Service List&lt;/h3&gt;
&lt;p&gt;This is the place where you can see the basic details of all the services which are registered in Service-Center. You can see the details like MicroService Name, Application Name, Status, Version, Creation time and Instance count. You can also un-register the microservice from Operations Tab if there is no running instances for the microservice.&lt;br /&gt;
&lt;img src=&quot;/assets/images/ServiceList.PNG&quot; alt=&quot;ServiceList&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;instance-details&quot;&gt;Instance Details&lt;/h3&gt;
&lt;p&gt;This is the place where you can see all the current running instances for the MicroService, you can get the list of endpoints and their protocols.&lt;br /&gt;
&lt;img src=&quot;/assets/images/InstanceList.PNG&quot; alt=&quot;InstanceList&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;provider-list&quot;&gt;Provider List&lt;/h3&gt;
&lt;p&gt;This is the place where you can get the list of all the providers for the MicroService.&lt;br /&gt;
&lt;img src=&quot;/assets/images/ProviderList.PNG&quot; alt=&quot;Provider List&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;consumer-list&quot;&gt;Consumer List&lt;/h3&gt;
&lt;p&gt;This is the place where you can get the list of all the consumers for the MicroService&lt;br /&gt;
&lt;img src=&quot;/assets/images/ConsumerList.PNG&quot; alt=&quot;Consumer List&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;schema-list&quot;&gt;Schema List&lt;/h3&gt;
&lt;p&gt;This is the place where we can get the list of all the Schema's for your MicroService, here you get options of viewing the Schema in Swagger form or Test the Schema on some particular instance. Here you also get an option to Download the Schema file in Html Client form.&lt;br /&gt;
&lt;img src=&quot;/assets/images/SchemaList.PNG&quot; alt=&quot;Schema List&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For Viewing the Schema in Swagger form you can click on Test Schema button and you can view the complete details of Schema in Swagger form.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/SchemaView.PNG&quot; alt=&quot;View Swagger&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you wish to test the Schema on some particular Instance then you can click on Test Schema and select the instance on which you want to test the Schema and then select the endpoints for that instance.&lt;br /&gt;
&lt;img src=&quot;/assets/images/SelectInstance.PNG&quot; alt=&quot;Select Instance&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once you selected the instance then you are ready for testing the Schema, you can input the required parameters for the Schema and hit on ‘Try it Out’ Button.&lt;br /&gt;
&lt;img src=&quot;/assets/images/Schematest.PNG&quot; alt=&quot;Schema Test&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;you-can-have-a-look-at-the-quick-start-guide-to-know-about-how-to-bring-up-the-management-console&quot;&gt;You can have a look at the &lt;a href=&quot;https://github.com/apache/incubator-servicecomb-service-center/tree/master/frontend#quickstart-guide&quot;&gt;Quick Start Guide&lt;/a&gt; to know about how to bring up the Management Console.&lt;/h5&gt;</content><author><name>Asif Siddiqui</name><email>mohammad.asif.siddiqui1@huawei.com</email><uri>http://asifdxtreme.github.io</uri></author><category term="service center" /><summary type="html">An introduction Service-Center Management Console</summary></entry><entry xml:lang="en"><title type="html">Service-Center Management UI Console</title><link href="/docs/service-center-ui/" rel="alternate" type="text/html" title="Service-Center Management UI Console" /><published>2017-10-28T00:00:00+08:00</published><updated>2017-10-30T09:18:43+08:00</updated><id>/docs/service-center-ui</id><content type="html" xml:base="/docs/service-center-ui/">&lt;p&gt;Service-Center Management UI Console enables user to view the list of MicroServices registered in SC.
Users can view the detailed information of their MicroServices, Instances and Schemas.
Service-Center UI also offers a unique feature of testing the Schemas of their MicroServices from UI, Users 
can also download the html client for their Schemas.&lt;/p&gt;

&lt;h3 id=&quot;preview-of-management-console&quot;&gt;Preview of Management Console&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/Service-Center-UI-Preview.gif&quot; alt=&quot;Preview&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;features&quot;&gt;Features&lt;/h3&gt;
&lt;p&gt;Service-Center Management console offers very useful features which makes users easy to use and manage service-center.&lt;/p&gt;

&lt;h3 id=&quot;dashboard&quot;&gt;Dashboard&lt;/h3&gt;
&lt;p&gt;This is the place where you can get the overall information about the services which are registered in your service-center like total number of services, providers, consumers and total instances. You can also get a list of Services which based on their current status.&lt;br /&gt;
&lt;img src=&quot;/assets/images/Dashboard.PNG&quot; alt=&quot;Dashboard&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;micro-service-list&quot;&gt;Micro-Service List&lt;/h3&gt;
&lt;p&gt;This is the place where you can see the basic details of all the services which are registered in Service-Center. You can see the details like MicroService Name, Application Name, Status, Version, Creation time and Instance count. You can also un-register the microservice from Operations Tab if there is no running instances for the microservice.&lt;br /&gt;
&lt;img src=&quot;/assets/images/ServiceList.PNG&quot; alt=&quot;ServiceList&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;instance-details&quot;&gt;Instance Details&lt;/h3&gt;
&lt;p&gt;This is the place where you can see all the current running instances for the MicroService, you can get the list of endpoints and their protocols.&lt;br /&gt;
&lt;img src=&quot;/assets/images/InstanceList.PNG&quot; alt=&quot;InstanceList&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;provider-list&quot;&gt;Provider List&lt;/h3&gt;
&lt;p&gt;This is the place where you can get the list of all the providers for the MicroService.&lt;br /&gt;
&lt;img src=&quot;/assets/images/ProviderList.PNG&quot; alt=&quot;Provider List&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;consumer-list&quot;&gt;Consumer List&lt;/h3&gt;
&lt;p&gt;This is the place where you can get the list of all the consumers for the MicroService&lt;br /&gt;
&lt;img src=&quot;/assets/images/ConsumerList.PNG&quot; alt=&quot;Consumer List&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;schema-list&quot;&gt;Schema List&lt;/h3&gt;
&lt;p&gt;This is the place where we can get the list of all the Schema's for your MicroService, here you get options of viewing the Schema in Swagger form or Test the Schema on some particular instance. Here you also get an option to Download the Schema file in Html Client form.&lt;br /&gt;
&lt;img src=&quot;/assets/images/SchemaList.PNG&quot; alt=&quot;Schema List&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For Viewing the Schema in Swagger form you can click on Test Schema button and you can view the complete details of Schema in Swagger form.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/SchemaView.PNG&quot; alt=&quot;View Swagger&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you wish to test the Schema on some particular Instance then you can click on Test Schema and select the instance on which you want to test the Schema and then select the endpoints for that instance.&lt;br /&gt;
&lt;img src=&quot;/assets/images/SelectInstance.PNG&quot; alt=&quot;Select Instance&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once you selected the instance then you are ready for testing the Schema, you can input the required parameters for the Schema and hit on ‘Try it Out’ Button.&lt;br /&gt;
&lt;img src=&quot;/assets/images/Schematest.PNG&quot; alt=&quot;Schema Test&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;you-can-have-a-look-at-the-quick-start-guide-to-know-about-how-to-bring-up-the-management-console&quot;&gt;You can have a look at the &lt;a href=&quot;https://github.com/apache/incubator-servicecomb-service-center/tree/master/frontend#quickstart-guide&quot;&gt;Quick Start Guide&lt;/a&gt; to know about how to bring up the Management Console.&lt;/h5&gt;</content><author><name>Asif Siddiqui</name><email>mohammad.asif.siddiqui1@huawei.com</email><uri>http://asifdxtreme.github.io</uri></author><category term="service center" /><summary type="html">An introduction Service-Center Management Console</summary></entry><entry xml:lang="cn"><title type="html">最头疼的遗留系统该如何改造？</title><link href="/cn/docs/how-to-reform-a-legacy-system/" rel="alternate" type="text/html" title="最头疼的遗留系统该如何改造？" /><published>2017-10-23T00:00:00+08:00</published><updated>2017-10-23T15:22:00+08:00</updated><id>/cn/docs/how-to-reform-a-legacy-system</id><content type="html" xml:base="/cn/docs/how-to-reform-a-legacy-system/">&lt;p&gt;随着RESTful、云计算、DevOps、持续交付等概念的深入人心，微服务（Microservices）逐渐成为系统架构的一个代名词。那么微服务是否是业界期待已久的架构解决方案？在对遗留系统进行微服务的改造过程中存在怎样的困难和挑战，应该注意些什么？在该分享中，王磊将通过实际的案例，跟大家探讨使用微服务改造遗留系统的实践之路。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;什么是微服务&lt;/li&gt;
  &lt;li&gt;微服务的诞生背景&lt;/li&gt;
  &lt;li&gt;遗留系统的微服务改造策略&lt;/li&gt;
  &lt;li&gt;微服务改造之路&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;什么是系统架构设计？&lt;/p&gt;

&lt;p&gt;一直以来，系统架构设计是IT领域经久不衰的话题之一，是每个系统构建过程中极其关键的一部分，它决定了系统是否能够被正确、有效的构建。架构师们也一直在持续探索，寻找更优秀的架构设计方式来构建系统。&lt;/p&gt;

&lt;p&gt;那什么是系统的架构设计？对于这个问题，我相信每个朋友都会有不同的定义，实际上，也并没有一个标准的答案来解释什么是架构设计。&lt;/p&gt;

&lt;p&gt;基于我过去的经验和工作方式，我认为系统架构设计的本质，是在应用系统内部找到这样一个动态平衡：平衡业务、技术、团队的同时，考虑系统灵活性、可扩展性以及可维护性等因素，并将应用系统划分成不同的部分，使这些部分彼此之间相互分工、相互协作，从而为用户提供某种特定的价值的方式。&lt;/p&gt;

&lt;p&gt;随着RESTful、云计算、DevOps、持续交付等概念的深入人心，&lt;strong&gt;微服务架构逐渐成为系统架构的一个代名词&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;什么是微服务架构&quot;&gt;什么是微服务架构&lt;/h2&gt;
&lt;p&gt;2015年，微服务架构这个词，以相当高的频率出现在各种演讲、文章、会议、社区上。这里，我先和大家快速回顾一下，Martin Fowler对微服务的抽象。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/microservice_definition_by_martin_folwer.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上所示，微服务架构的核心四要素，我用红色标注出来了。如果翻译成中文，大致如下所示：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。 每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相协作（通常是基于HTTP协议的RESTful API）。 每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。 另外，对具体的服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;总结成一句话就是&lt;strong&gt;微服务是围绕业务构建的细粒度的分布式系统&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;微服务的诞生背景&quot;&gt;微服务的诞生背景&lt;/h2&gt;
&lt;p&gt;2015年，微服务突然火了，为什么？&lt;/p&gt;

&lt;p&gt;其实微服务架构并不是技术创新，而是IT发展到现阶段对技术架构的一种阐释。&lt;/p&gt;

&lt;p&gt;它要求包括&lt;strong&gt;快速和业务对齐（aligning business）、理解和抽象业务（基于领域建模）、快速开发（Lean、Agile）、快速反馈和交付（CI、CD、DevOps）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;所以说，微服务并不是技术，而是将化整为零（或称分治）思想换了一种说法，无论是把一个大型系统分割成多个小而自治的系统，还是把一个大型团队分成多个团队，或是把一个复杂的项目分成多个交付阶段都是这种思想的运用。&lt;/p&gt;

&lt;p&gt;当然，任何新事物的诞生，总会有一个推动因素。微服务的诞生也并非偶然。它是互联网高速发展，技术日新月异的变化以及传统架构无法适应快速变化等多重因素的推动下所诞生的产物。&lt;/p&gt;

&lt;p&gt;基于个人的理解，我将微服务的诞生因素总结为如下几点：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/why_microservice_show_up.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;互联网行业的快速发展&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;过去的十年中，互联网对我们的生活产生了翻天覆地的变化，越来越多的传统行业公司也开始依赖互联网技术打造其核心竞争优势。&lt;/p&gt;

    &lt;p&gt;在这种情况下，如何从系统架构的角度出发，构建灵活、易扩展的系统，快速应对需求的变化；同时，随着用户量的增加，如何保证系统的可伸缩性、高可用性，成为系统架构面临的挑战。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;单块架构系统面临的挑战&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;随着用户需求个性化、产品生命周期变短、市场需求不稳定等因素的出现，单块架构系统面临着越来越多的挑战。如何找到一种更有效的、更灵活、适应需求的系统架构方式，成为大家关注的焦点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;敏捷、精益方法、持续交付的深入人心&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;在IT行业发展的过去十年，敏捷、精益、持续交付等价值观、方法论的提出以及实践，让很多组织意识到应变市场变化、提高响应力的重要性，应该构建软件交付周期的闭环（分析、开发、测试、部署、运维、监控、运营），而不仅仅是提高开发阶段的效率。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;精益创业（Lean Startup）&lt;/strong&gt;帮助组织分析并建立最小可实行产品（MinimumViableProduct），通过迭代持续改进敏捷方法帮助组织消除浪费，通过反馈不断找到正确的方向。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;持续交付&lt;/strong&gt;则帮助组织构建更快、更可靠、可频繁发布的交付机制并构建产品交付闭环。&lt;/p&gt;

    &lt;p&gt;大部分组织已经基本上形成了一套可实施的交付体系。包括持续集成、自动化测试、数据管理、自动化部署机制等。&lt;/p&gt;

    &lt;p&gt;这时候，大泥球式的单块架构，会逐渐成为影响交付周期进一步优化的瓶颈，因此如何找到灵活性高、扩展性好的架构方式，也成为进一步优化交付周期面临的挑战。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Docker等容器虚拟化技术的快速发展&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;同传统的虚拟化技术相比，基于容器技术的Docker，不需要复杂的Hypervisor机制支持，具有更高的虚拟化性能和效率。&lt;/p&gt;

    &lt;p&gt;同时容器可以很容易的运行在任意的装有DockerEngine的系统上，使得开发人员能够用更低的成本将应用程序部署在不同平台上。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DevOps文化&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;DevOps文化的推行打破了传统开发与运维之间的壁垒，帮助组织形成开发、运维紧密配合的、全功能化的高效团队，并尽早降低软件交付最后一公里的风险。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;遗留系统的微服务改造策略&quot;&gt;遗留系统的微服务改造策略&lt;/h2&gt;
&lt;p&gt;聊完什么是微服务架构以及其诞生背景，接下来我们来谈谈如何改造遗留系统。&lt;/p&gt;

&lt;p&gt;在过去的10多年间，大部分工作时间我都在和遗留系统打交道。我相信很多朋友也是工作在已经运转多年的遗留系统上。&lt;/p&gt;

&lt;p&gt;对于这类系统，当谈论使用微服务对其进行改造时，我认为要谨记一点：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;改造不是重做。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在改造的过程中，要始终以保证系统为用户提供的业务价值可用作为首要目标。&lt;/strong&gt;从这个点出发，基于我的经验，对微服务改造的策略总结为如下五个步骤：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/microservice_reform_strategy.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;范围定义&lt;/p&gt;

    &lt;p&gt;对于遗留系统而言，通常业务运转时间较长（譬如5~8年以上，甚至更长），因此涉及的功能繁杂，代码中存在大量无效或者过时的需求，缺陷修复成本较高。&lt;/p&gt;

    &lt;p&gt;另外，系统在演进的过程中，也会持续为用户提供新的功能和价值。因此，划分出清晰的范围非常重要。&lt;/p&gt;

    &lt;p&gt;实际上，范围定义主要包括两部分：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;明确业务改造范围&lt;/p&gt;

        &lt;p&gt;所谓改造范围，就是确定我们常说的业务试点。通常，作为初次尝试微服务实践的组织，建议选取业务范围影响较小、非关键功能的试点，这样做也是为了确保在不影响核心业务的情况下快速尝试并获得反馈。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;明确成员责任范围&lt;/p&gt;

        &lt;p&gt;明确成员责任范围，确定由谁来改造，确保改造的目标清晰。&lt;/p&gt;

        &lt;p&gt;实际上，对于产品而言，遗留系统的维护和更新，包括缺陷定位、缺陷修复、数据更新、功能实现、测试、交付给运维团队等，通常已经让团队的工作处于高负荷状态。因此，需要确定成员，全身心的投入，以微服务改造作为短期目标。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;功能剥离&lt;/p&gt;

    &lt;p&gt;有了明确的业务范围，成员也有了清晰的责任，接下来就需要将部分功能点进行剥离。&lt;/p&gt;

    &lt;p&gt;所谓剥离，就是将选中的功能从原有的系统中拆分出来，并构建成独立的服务。在这个阶段，主要包括两点：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;将功能从原有系统拆分出来，并构建新服务&lt;/p&gt;

        &lt;p&gt;一提到拆分，很多朋友会纠结，“系统复杂，如何拆分微服务才好？怎么样的拆分才合理？”。其实，从我个人的观点来看，这时候还不是纠结服务到底怎么划分合理的时候。为什么？&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;好的架构是动态演变和迭代出来的，业务在不断改变，技术和工具也在不会的升级换代，没有完美的架构，只有无限逼近完美的动态平衡，所以先小范围、低成本动起来，在运转中找平衡点。&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;微服务的复杂度在于分布式系统本身，以及其生态系统（开发、测试、部署、运维、监控、告警）的搭建。&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;团队文化的形成是一个相对漫长的过程，如果花很大力气关注服务怎么拆，而没有聚焦在生态系统的搭建以及团队文化的形成上，实际上是舍本逐末。即便拆分出了不同的服务，在落地的时候也会遇到诸多问题。所以，找一个功能点先拆，然后搭建持续交付流水线，快速试错，建立好有效的反馈闭环机制，再不断寻找动态平衡，拆分出更细的服务或者将不合理的服务合并。&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在原有的系统前端，使用代理机制，并使用遗留系统和新服务组合为用户提供价值&lt;/p&gt;

        &lt;p&gt;这一步，目的是使用组合的系统（遗留系统+新的服务）为用户提供价值。&lt;/p&gt;

        &lt;p&gt;对于Web系统，通常可以在前端使用直接请求新的服务。也可以在后端使用转发请求，获取新服务提供的数据。&lt;/p&gt;

        &lt;p&gt;如下图所示：&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/assets/images/microservice_reform_strategy.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据解耦&lt;/p&gt;

    &lt;p&gt;在以前的遗留系统构建过程中，通常使用数据库作为集成点，不同功能/系统之间通过数据库完成数据交换。对于某些系统，还大量使用存储过程完成业务逻辑，开发的时候看似效率高，但几年下来，DBA成了IT团队最懂业务的人，维护成为瓶颈。&lt;/p&gt;

    &lt;p&gt;而实际上，业务的数据是业务固有的组成部分，应当随着业务的变化而变化。业务拆分出来，数据也应该拆分出来。从而保证访问数据只能通过统一的相关业务API完成。便于在将来的业务和架构演进中，有效的对数据维护、管理和升级。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据同步&lt;/p&gt;

    &lt;p&gt;数据同步，是一个价值体现的过渡过程。&lt;/p&gt;

    &lt;p&gt;一方面，遗留系统的改造中存在的各种各样的挑战和我们今天认为的不合理（当时的场景也许是合理的）。另一方面，对于大部分遗留的系统，都会使用数据库作为集成点（开发成本低），导致某业务功能的数据与其他功能有着千丝万缕的联系，数据的变化容易对其他功能造成影响。&lt;/p&gt;

    &lt;p&gt;因此对于大型的遗留系统，很难在短期的时间内（3~6个月）完成全系统的改造。需要一个相对漫长，循序渐进的过程来完成改造。&lt;/p&gt;

    &lt;p&gt;譬如，在电商系统中，商家的后台管理系统中的产品、价格的更新，会发布到面向用户的电商搜索系统中以及其他系统中。如果我们将系统中的产品相关拆分成独立服务，则必须也要拆分数据发布机制，否则的话容易造成数据不一致。但拆分数据发布机制，又需要分析清楚不同数据之间的影响和依赖，需要更大的成本，短期内不易完成。&lt;/p&gt;

    &lt;p&gt;这时候，如果将新服务的数据同步回原有的数据库，采用这样一个折中的的过程，既能保障新的服务和数据被独立，又不影响原有的遗留系统功能。&lt;/p&gt;

    &lt;p&gt;说白了，这其实也是在保证系统为用户提供的业务价值不被破坏。&lt;/p&gt;

    &lt;p&gt;有了之前的尝试，接下来就是通过不断的迭代，完成功能剥离，数据解耦、数据同步，从而将更多的功能拆分成独立的服务。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/legacy_system_reform_strategy.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上就是我对于遗留系统改造的策略。&lt;/p&gt;

&lt;h2 id=&quot;遗留系统改造实践&quot;&gt;遗留系统改造实践&lt;/h2&gt;
&lt;p&gt;接下来，我和大家分享一个我所经历的遗留系统改造的案例。首先，让我们看看这个系统的背景和一些数据。&lt;/p&gt;

&lt;h3 id=&quot;客户背景&quot;&gt;客户背景&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://movit-tech.com/&quot;&gt;盟拓软件&lt;/a&gt;是中国房地产行业IT服务及行业解决方案和产品的领先厂家，其依据市场变化推出全民卖房的新营销模式，正从线下的传统现场售楼模式向线上的房地产电商模式进行转变。&lt;/p&gt;

&lt;h3 id=&quot;业务痛点&quot;&gt;业务痛点&lt;/h3&gt;

&lt;p&gt;当今房地产行业呈现短期开盘峰值、后期零星散客的业务特性。其面临着高昂线下运营成本，营销成本占销售额&amp;gt;5%。而由此引入的线上竞价秒杀营销模式，传统IT解决方案的系统资源率、峰值扩容能力将无法满足。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/case_mengtuo_traditional_mode.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;系统概览&quot;&gt;系统概览&lt;/h3&gt;

&lt;p&gt;系统为典型的三层单块架构，使用MySQL数据库存储数据。运行在服务器上的应用处理性能较低，为了应对短暂的访问高峰，额外购置了较多的服务器资源，访问高峰过后，服务器资源闲置造成较大浪费，且需要较多人员维护。&lt;/p&gt;

&lt;h3 id=&quot;相关数据&quot;&gt;相关数据&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;代码约&lt;strong&gt;100万&lt;/strong&gt;行，测试覆盖率为&lt;strong&gt;10%&lt;/strong&gt;，集成测试时间为&lt;strong&gt;一个月&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;代码臃肿，无效遗留代码较多，且业务间紧耦合，测试覆盖率较低，测试出问题了难以定位，导致测试耗时较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;营销预案需&lt;strong&gt;提前1个月&lt;/strong&gt;准备资源&lt;/p&gt;

    &lt;p&gt;为应对访问高峰，每次都需要预购大量的服务资源，重新部署环境，并运行相关测试。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;业务耦合紧，新业务上线&lt;strong&gt;&amp;gt;半年&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;每次测试都要多个业务团队联合测试，问题定位较耗时，测试效率低。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;上百种业务，2-3种开发语言&lt;/p&gt;

    &lt;p&gt;业务复杂，且语言不一，系统联调时耗时较多且需相互配合，时间周期较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;运维团队&lt;strong&gt;&amp;gt;20人&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;臃肿的团队导致问题定位需多方配合，沟通成本高。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;基于之前定义的改造策略，我们的改造过程大致如下所示：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;范围定义：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将原房地产CRM平台按业务类别拆分为多个微服务。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/images/case_mengtuo_reform_before_and_after.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;功能剥离：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从单体CRM系统中逐步拆分出业务模块（服务网关、客户服务、房源服务、机会服务、积分服务）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据解耦&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每个微服务的数据进行独立存储。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据同步&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在负载较低时，将数据同步回原有的遗留系统中不断迭代，陆续完成后续的服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;改造过程中，基于ServiceComb，&lt;strong&gt;通过控制请求路由，逐步架空对原单体应用的请求， 平滑过渡系统到微服务架构。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;单个服务的构建并没有那么复杂，基于ServiceComb，通过如下的简单4步，即可快速完成改造：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;引入&lt;a href=&quot;https://github.com/apache/incubator-servicecomb-java-chassis&quot;&gt;ServiceComb Java Chassis&lt;/a&gt;框架依赖&lt;/li&gt;
  &lt;li&gt;定义服务接口端点&lt;/li&gt;
  &lt;li&gt;添加服务配置文件&lt;/li&gt;
  &lt;li&gt;注释服务启动入口&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;另外，通过Company Workshop中提供的Docker插件配置，10分钟内完成了服务容器化，自动生成镜像。&lt;/p&gt;

&lt;p&gt;同时，利用ServiceComb开发的微服务应用，可同时无缝接入&lt;a href=&quot;https://www.huaweicloud.com/product/servicestage.html&quot;&gt;ServiceStage&lt;/a&gt;，享受到微服务治理、容器虚机混编、应用拓扑等能力。&lt;/p&gt;

&lt;p&gt;为应对短暂的业务高峰，经常需要预购大量的资源来提前部署和验证环境，花费大量的人力物力，且资源利用率极低。因此，进行云化改造后的产品和解决方案需要具备随着参与人数增加而秒级伸缩，支撑业务峰值和资源利用率的能力。盟拓软件基于华为ServiceStage的核心技术容器改造、混编方案、编排调度算法等进行容器虚机混编应用云化改造，实现了应用的秒级部署和弹性伸缩能力，极大地提高了资源的利用率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;改造后效果：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;运维人力&lt;strong&gt;减少80%&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;资源利用率&lt;strong&gt;提升50%&lt;/strong&gt;，大幅降低运营成本&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;每秒万级&lt;/strong&gt;调用链分析能力&lt;/li&gt;
  &lt;li&gt;传统系统和应用平滑改造上云&lt;/li&gt;
  &lt;li&gt;互联网营销模式，天粒度业务快速创新&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/case_mengtuo_new_mode.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;理论上，经过不断地迭代，逐渐完成业务功能解耦，新服务构建。那么遗留系统就会被替换掉。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;改造要点&quot;&gt;改造要点&lt;/h2&gt;
&lt;p&gt;在改造的整个过程中，我认为如下几个实践是非常重要的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/best_practices_for_legacy_system_reform.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;基础设施自动化&quot;&gt;基础设施自动化&lt;/h3&gt;
&lt;p&gt;原有的部署发生在数据中心，因此流程上相对复杂，而且存在一定弊端（譬如审批和协作上，起不到实质作用）。对于改造后的服务而言，我们使用更多的自动化方式代替复杂的审批流程。通过使用华为ServiceStage作为基础设施，团队能够更自主的对基础设施进行管理。如资源创建、销毁、更新等。随着服务的增多，基础设施自动化帮助我们节省了大量的时间。当然，从组织层面，也成立了专门的小组研究华为ServiceStage以及相关的DevOps配套工具。&lt;/p&gt;

&lt;p&gt;目前，国内外有很多优秀的云平台，可以方便的为用户提供基础设施的自动化机制。&lt;/p&gt;

&lt;h3 id=&quot;微服务生态系统&quot;&gt;微服务生态系统&lt;/h3&gt;
&lt;p&gt;微服务的生态系统是指微服务实施过程相关的协作部分，涉及部分较多，譬如测试机制、持续集成、自动化部署、细粒度监控、日志聚合、告警、持续交付，以及大家非常关注的服务注册、服务发现机制等。&lt;/p&gt;

&lt;p&gt;这部分的灵活性比较大，因为目前如上说的每一个领域都有很多优秀的工具。譬如日志聚合目前业界的方案通常为ELK，监控的方案如Zabbix、NewRelic、CloudWatch等，成熟的监控工具都具有告警功能，PagerDuty也提供更专业的告警服务。服务注册和发现有ServiceComb框架的Service Center，Eureka，Consul，Zookeeper。大家可以在各自的团队中自由发挥。&lt;/p&gt;

&lt;h3 id=&quot;开发框架的演进&quot;&gt;开发框架的演进&lt;/h3&gt;
&lt;p&gt;开发框架是团队在构建微服务的过程中，不断总结，梳理出的快速开发微服务的相关工具和框架。&lt;/p&gt;

&lt;p&gt;我们基于ServiceComb构建了快速开发框架，主要包括四部分，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rapid_development_framework.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;微服务工程示例&lt;/p&gt;

    &lt;p&gt;提供微服务改造架构最佳实践参考工程Company，使能微服务改造或开发能复用其架构设计和配置，同时指导实现服务容器化和后续服务性能测试等提高服务可靠性。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;契约生成工具&lt;/p&gt;

    &lt;p&gt;ServiceComb采用了基于OpenAPI的服务契约，使业务逻辑与编程语言解耦，并可使用Swagger工具定义服务契约，自动生成契约对应的代码和文档。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;持续集成&lt;/p&gt;

    &lt;p&gt;持续集成使用了Jenkins，通过其配置文件定义主要的阶段：&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;验证：运行单元测试，集成测试&lt;/p&gt;

      &lt;p&gt;构建：构建可执行的jar部署包&lt;/p&gt;

      &lt;p&gt;部署：基于指定版本制作镜像，并推送到测试或生产环境下&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;利用这样的持续集成模板工程，花费很少的时间，就可以针对新建的微服务应用，快速配置其对应的持续集成环境。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kubernetes集群一键部署&lt;/p&gt;

    &lt;p&gt;Kubernetes是谷歌开源的一个容器集群管理工具。基于Kubernetes，可实现微服务的快速部署及弹性伸缩。我们提供了一键部署脚本，部署时只需稍作修改即可通过一条命令，自动完成资源的创建、部署、弹性伸缩、金丝雀发布等。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;团队运维自管理&quot;&gt;团队运维自管理&lt;/h3&gt;

&lt;p&gt;这一部分是关于团队的文化管理。也是对DevOPS的延伸，我们称为TMI（Team Managed Infrastructure）。&lt;/p&gt;

&lt;p&gt;目的是将分析、开发、测试以及资源创建、销毁、自动化部署的权利交给团队，由团队按需完成部署（加上看板的流程管理，而非Scrum的固定迭代，可以做到一天部署多次）。&lt;/p&gt;

&lt;p&gt;当然，这个环节非常依赖于成熟的监控以及告警机制，当出现问题时，能够有效的通知到责任人，快速反馈，快速修复。团队内部也会定期轮换Pager（出问题救火的人），培养团队以服务可用作为大家的共同目标，培养产品观念，而非项目观念。&lt;/p&gt;

&lt;p&gt;再回顾一下这个图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/best_practices_for_legacy_system_reform.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后，和大家分享一下，我个人在微服务实施过程中总结的4句方针:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由大到小，由粗到细&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关注运维，关注监控&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;快速反馈，快速修复&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;循序渐进，增量实现&lt;/strong&gt;&lt;/p&gt;</content><author><name>Wang Lei</name><email>wanglei177@huawei.com</email><uri>https://wldandan.github.io</uri></author><category term="系统改造" /><summary type="html">微服务是否是业界期待已久的企业架构解决方案？在对遗留系统进行微服务的改造过程中存在怎样的困难和挑战，应该注意些什么？</summary></entry><entry xml:lang="en"><title type="html">最头疼的遗留系统该如何改造？</title><link href="/docs/how-to-reform-a-legacy-system/" rel="alternate" type="text/html" title="最头疼的遗留系统该如何改造？" /><published>2017-10-23T00:00:00+08:00</published><updated>2017-10-23T15:22:00+08:00</updated><id>/docs/how-to-reform-a-legacy-system</id><content type="html" xml:base="/docs/how-to-reform-a-legacy-system/">&lt;p&gt;随着RESTful、云计算、DevOps、持续交付等概念的深入人心，微服务（Microservices）逐渐成为系统架构的一个代名词。那么微服务是否是业界期待已久的架构解决方案？在对遗留系统进行微服务的改造过程中存在怎样的困难和挑战，应该注意些什么？在该分享中，王磊将通过实际的案例，跟大家探讨使用微服务改造遗留系统的实践之路。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;什么是微服务&lt;/li&gt;
  &lt;li&gt;微服务的诞生背景&lt;/li&gt;
  &lt;li&gt;遗留系统的微服务改造策略&lt;/li&gt;
  &lt;li&gt;微服务改造之路&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;什么是系统架构设计？&lt;/p&gt;

&lt;p&gt;一直以来，系统架构设计是IT领域经久不衰的话题之一，是每个系统构建过程中极其关键的一部分，它决定了系统是否能够被正确、有效的构建。架构师们也一直在持续探索，寻找更优秀的架构设计方式来构建系统。&lt;/p&gt;

&lt;p&gt;那什么是系统的架构设计？对于这个问题，我相信每个朋友都会有不同的定义，实际上，也并没有一个标准的答案来解释什么是架构设计。&lt;/p&gt;

&lt;p&gt;基于我过去的经验和工作方式，我认为系统架构设计的本质，是在应用系统内部找到这样一个动态平衡：平衡业务、技术、团队的同时，考虑系统灵活性、可扩展性以及可维护性等因素，并将应用系统划分成不同的部分，使这些部分彼此之间相互分工、相互协作，从而为用户提供某种特定的价值的方式。&lt;/p&gt;

&lt;p&gt;随着RESTful、云计算、DevOps、持续交付等概念的深入人心，&lt;strong&gt;微服务架构逐渐成为系统架构的一个代名词&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;什么是微服务架构&quot;&gt;什么是微服务架构&lt;/h2&gt;
&lt;p&gt;2015年，微服务架构这个词，以相当高的频率出现在各种演讲、文章、会议、社区上。这里，我先和大家快速回顾一下，Martin Fowler对微服务的抽象。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/microservice_definition_by_martin_folwer.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上所示，微服务架构的核心四要素，我用红色标注出来了。如果翻译成中文，大致如下所示：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。 每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相协作（通常是基于HTTP协议的RESTful API）。 每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。 另外，对具体的服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;总结成一句话就是&lt;strong&gt;微服务是围绕业务构建的细粒度的分布式系统&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;微服务的诞生背景&quot;&gt;微服务的诞生背景&lt;/h2&gt;
&lt;p&gt;2015年，微服务突然火了，为什么？&lt;/p&gt;

&lt;p&gt;其实微服务架构并不是技术创新，而是IT发展到现阶段对技术架构的一种阐释。&lt;/p&gt;

&lt;p&gt;它要求包括&lt;strong&gt;快速和业务对齐（aligning business）、理解和抽象业务（基于领域建模）、快速开发（Lean、Agile）、快速反馈和交付（CI、CD、DevOps）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;所以说，微服务并不是技术，而是将化整为零（或称分治）思想换了一种说法，无论是把一个大型系统分割成多个小而自治的系统，还是把一个大型团队分成多个团队，或是把一个复杂的项目分成多个交付阶段都是这种思想的运用。&lt;/p&gt;

&lt;p&gt;当然，任何新事物的诞生，总会有一个推动因素。微服务的诞生也并非偶然。它是互联网高速发展，技术日新月异的变化以及传统架构无法适应快速变化等多重因素的推动下所诞生的产物。&lt;/p&gt;

&lt;p&gt;基于个人的理解，我将微服务的诞生因素总结为如下几点：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/why_microservice_show_up.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;互联网行业的快速发展&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;过去的十年中，互联网对我们的生活产生了翻天覆地的变化，越来越多的传统行业公司也开始依赖互联网技术打造其核心竞争优势。&lt;/p&gt;

    &lt;p&gt;在这种情况下，如何从系统架构的角度出发，构建灵活、易扩展的系统，快速应对需求的变化；同时，随着用户量的增加，如何保证系统的可伸缩性、高可用性，成为系统架构面临的挑战。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;单块架构系统面临的挑战&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;随着用户需求个性化、产品生命周期变短、市场需求不稳定等因素的出现，单块架构系统面临着越来越多的挑战。如何找到一种更有效的、更灵活、适应需求的系统架构方式，成为大家关注的焦点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;敏捷、精益方法、持续交付的深入人心&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;在IT行业发展的过去十年，敏捷、精益、持续交付等价值观、方法论的提出以及实践，让很多组织意识到应变市场变化、提高响应力的重要性，应该构建软件交付周期的闭环（分析、开发、测试、部署、运维、监控、运营），而不仅仅是提高开发阶段的效率。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;精益创业（Lean Startup）&lt;/strong&gt;帮助组织分析并建立最小可实行产品（MinimumViableProduct），通过迭代持续改进敏捷方法帮助组织消除浪费，通过反馈不断找到正确的方向。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;持续交付&lt;/strong&gt;则帮助组织构建更快、更可靠、可频繁发布的交付机制并构建产品交付闭环。&lt;/p&gt;

    &lt;p&gt;大部分组织已经基本上形成了一套可实施的交付体系。包括持续集成、自动化测试、数据管理、自动化部署机制等。&lt;/p&gt;

    &lt;p&gt;这时候，大泥球式的单块架构，会逐渐成为影响交付周期进一步优化的瓶颈，因此如何找到灵活性高、扩展性好的架构方式，也成为进一步优化交付周期面临的挑战。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Docker等容器虚拟化技术的快速发展&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;同传统的虚拟化技术相比，基于容器技术的Docker，不需要复杂的Hypervisor机制支持，具有更高的虚拟化性能和效率。&lt;/p&gt;

    &lt;p&gt;同时容器可以很容易的运行在任意的装有DockerEngine的系统上，使得开发人员能够用更低的成本将应用程序部署在不同平台上。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DevOps文化&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;DevOps文化的推行打破了传统开发与运维之间的壁垒，帮助组织形成开发、运维紧密配合的、全功能化的高效团队，并尽早降低软件交付最后一公里的风险。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;遗留系统的微服务改造策略&quot;&gt;遗留系统的微服务改造策略&lt;/h2&gt;
&lt;p&gt;聊完什么是微服务架构以及其诞生背景，接下来我们来谈谈如何改造遗留系统。&lt;/p&gt;

&lt;p&gt;在过去的10多年间，大部分工作时间我都在和遗留系统打交道。我相信很多朋友也是工作在已经运转多年的遗留系统上。&lt;/p&gt;

&lt;p&gt;对于这类系统，当谈论使用微服务对其进行改造时，我认为要谨记一点：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;改造不是重做。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在改造的过程中，要始终以保证系统为用户提供的业务价值可用作为首要目标。&lt;/strong&gt;从这个点出发，基于我的经验，对微服务改造的策略总结为如下五个步骤：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/microservice_reform_strategy.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;范围定义&lt;/p&gt;

    &lt;p&gt;对于遗留系统而言，通常业务运转时间较长（譬如5~8年以上，甚至更长），因此涉及的功能繁杂，代码中存在大量无效或者过时的需求，缺陷修复成本较高。&lt;/p&gt;

    &lt;p&gt;另外，系统在演进的过程中，也会持续为用户提供新的功能和价值。因此，划分出清晰的范围非常重要。&lt;/p&gt;

    &lt;p&gt;实际上，范围定义主要包括两部分：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;明确业务改造范围&lt;/p&gt;

        &lt;p&gt;所谓改造范围，就是确定我们常说的业务试点。通常，作为初次尝试微服务实践的组织，建议选取业务范围影响较小、非关键功能的试点，这样做也是为了确保在不影响核心业务的情况下快速尝试并获得反馈。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;明确成员责任范围&lt;/p&gt;

        &lt;p&gt;明确成员责任范围，确定由谁来改造，确保改造的目标清晰。&lt;/p&gt;

        &lt;p&gt;实际上，对于产品而言，遗留系统的维护和更新，包括缺陷定位、缺陷修复、数据更新、功能实现、测试、交付给运维团队等，通常已经让团队的工作处于高负荷状态。因此，需要确定成员，全身心的投入，以微服务改造作为短期目标。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;功能剥离&lt;/p&gt;

    &lt;p&gt;有了明确的业务范围，成员也有了清晰的责任，接下来就需要将部分功能点进行剥离。&lt;/p&gt;

    &lt;p&gt;所谓剥离，就是将选中的功能从原有的系统中拆分出来，并构建成独立的服务。在这个阶段，主要包括两点：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;将功能从原有系统拆分出来，并构建新服务&lt;/p&gt;

        &lt;p&gt;一提到拆分，很多朋友会纠结，“系统复杂，如何拆分微服务才好？怎么样的拆分才合理？”。其实，从我个人的观点来看，这时候还不是纠结服务到底怎么划分合理的时候。为什么？&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;
            &lt;p&gt;好的架构是动态演变和迭代出来的，业务在不断改变，技术和工具也在不会的升级换代，没有完美的架构，只有无限逼近完美的动态平衡，所以先小范围、低成本动起来，在运转中找平衡点。&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;微服务的复杂度在于分布式系统本身，以及其生态系统（开发、测试、部署、运维、监控、告警）的搭建。&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;
            &lt;p&gt;团队文化的形成是一个相对漫长的过程，如果花很大力气关注服务怎么拆，而没有聚焦在生态系统的搭建以及团队文化的形成上，实际上是舍本逐末。即便拆分出了不同的服务，在落地的时候也会遇到诸多问题。所以，找一个功能点先拆，然后搭建持续交付流水线，快速试错，建立好有效的反馈闭环机制，再不断寻找动态平衡，拆分出更细的服务或者将不合理的服务合并。&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在原有的系统前端，使用代理机制，并使用遗留系统和新服务组合为用户提供价值&lt;/p&gt;

        &lt;p&gt;这一步，目的是使用组合的系统（遗留系统+新的服务）为用户提供价值。&lt;/p&gt;

        &lt;p&gt;对于Web系统，通常可以在前端使用直接请求新的服务。也可以在后端使用转发请求，获取新服务提供的数据。&lt;/p&gt;

        &lt;p&gt;如下图所示：&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/assets/images/microservice_reform_strategy.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据解耦&lt;/p&gt;

    &lt;p&gt;在以前的遗留系统构建过程中，通常使用数据库作为集成点，不同功能/系统之间通过数据库完成数据交换。对于某些系统，还大量使用存储过程完成业务逻辑，开发的时候看似效率高，但几年下来，DBA成了IT团队最懂业务的人，维护成为瓶颈。&lt;/p&gt;

    &lt;p&gt;而实际上，业务的数据是业务固有的组成部分，应当随着业务的变化而变化。业务拆分出来，数据也应该拆分出来。从而保证访问数据只能通过统一的相关业务API完成。便于在将来的业务和架构演进中，有效的对数据维护、管理和升级。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据同步&lt;/p&gt;

    &lt;p&gt;数据同步，是一个价值体现的过渡过程。&lt;/p&gt;

    &lt;p&gt;一方面，遗留系统的改造中存在的各种各样的挑战和我们今天认为的不合理（当时的场景也许是合理的）。另一方面，对于大部分遗留的系统，都会使用数据库作为集成点（开发成本低），导致某业务功能的数据与其他功能有着千丝万缕的联系，数据的变化容易对其他功能造成影响。&lt;/p&gt;

    &lt;p&gt;因此对于大型的遗留系统，很难在短期的时间内（3~6个月）完成全系统的改造。需要一个相对漫长，循序渐进的过程来完成改造。&lt;/p&gt;

    &lt;p&gt;譬如，在电商系统中，商家的后台管理系统中的产品、价格的更新，会发布到面向用户的电商搜索系统中以及其他系统中。如果我们将系统中的产品相关拆分成独立服务，则必须也要拆分数据发布机制，否则的话容易造成数据不一致。但拆分数据发布机制，又需要分析清楚不同数据之间的影响和依赖，需要更大的成本，短期内不易完成。&lt;/p&gt;

    &lt;p&gt;这时候，如果将新服务的数据同步回原有的数据库，采用这样一个折中的的过程，既能保障新的服务和数据被独立，又不影响原有的遗留系统功能。&lt;/p&gt;

    &lt;p&gt;说白了，这其实也是在保证系统为用户提供的业务价值不被破坏。&lt;/p&gt;

    &lt;p&gt;有了之前的尝试，接下来就是通过不断的迭代，完成功能剥离，数据解耦、数据同步，从而将更多的功能拆分成独立的服务。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/legacy_system_reform_strategy.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上就是我对于遗留系统改造的策略。&lt;/p&gt;

&lt;h2 id=&quot;遗留系统改造实践&quot;&gt;遗留系统改造实践&lt;/h2&gt;
&lt;p&gt;接下来，我和大家分享一个我所经历的遗留系统改造的案例。首先，让我们看看这个系统的背景和一些数据。&lt;/p&gt;

&lt;h3 id=&quot;客户背景&quot;&gt;客户背景&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://movit-tech.com/&quot;&gt;盟拓软件&lt;/a&gt;是中国房地产行业IT服务及行业解决方案和产品的领先厂家，其依据市场变化推出全民卖房的新营销模式，正从线下的传统现场售楼模式向线上的房地产电商模式进行转变。&lt;/p&gt;

&lt;h3 id=&quot;业务痛点&quot;&gt;业务痛点&lt;/h3&gt;

&lt;p&gt;当今房地产行业呈现短期开盘峰值、后期零星散客的业务特性。其面临着高昂线下运营成本，营销成本占销售额&amp;gt;5%。而由此引入的线上竞价秒杀营销模式，传统IT解决方案的系统资源率、峰值扩容能力将无法满足。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/case_mengtuo_traditional_mode.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;系统概览&quot;&gt;系统概览&lt;/h3&gt;

&lt;p&gt;系统为典型的三层单块架构，使用MySQL数据库存储数据。运行在服务器上的应用处理性能较低，为了应对短暂的访问高峰，额外购置了较多的服务器资源，访问高峰过后，服务器资源闲置造成较大浪费，且需要较多人员维护。&lt;/p&gt;

&lt;h3 id=&quot;相关数据&quot;&gt;相关数据&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;代码约&lt;strong&gt;100万&lt;/strong&gt;行，测试覆盖率为&lt;strong&gt;10%&lt;/strong&gt;，集成测试时间为&lt;strong&gt;一个月&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;代码臃肿，无效遗留代码较多，且业务间紧耦合，测试覆盖率较低，测试出问题了难以定位，导致测试耗时较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;营销预案需&lt;strong&gt;提前1个月&lt;/strong&gt;准备资源&lt;/p&gt;

    &lt;p&gt;为应对访问高峰，每次都需要预购大量的服务资源，重新部署环境，并运行相关测试。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;业务耦合紧，新业务上线&lt;strong&gt;&amp;gt;半年&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;每次测试都要多个业务团队联合测试，问题定位较耗时，测试效率低。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;上百种业务，2-3种开发语言&lt;/p&gt;

    &lt;p&gt;业务复杂，且语言不一，系统联调时耗时较多且需相互配合，时间周期较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;运维团队&lt;strong&gt;&amp;gt;20人&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;臃肿的团队导致问题定位需多方配合，沟通成本高。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;基于之前定义的改造策略，我们的改造过程大致如下所示：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;范围定义：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将原房地产CRM平台按业务类别拆分为多个微服务。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/images/case_mengtuo_reform_before_and_after.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;功能剥离：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从单体CRM系统中逐步拆分出业务模块（服务网关、客户服务、房源服务、机会服务、积分服务）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据解耦&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每个微服务的数据进行独立存储。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据同步&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在负载较低时，将数据同步回原有的遗留系统中不断迭代，陆续完成后续的服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;改造过程中，基于ServiceComb，&lt;strong&gt;通过控制请求路由，逐步架空对原单体应用的请求， 平滑过渡系统到微服务架构。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;单个服务的构建并没有那么复杂，基于ServiceComb，通过如下的简单4步，即可快速完成改造：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;引入&lt;a href=&quot;https://github.com/apache/incubator-servicecomb-java-chassis&quot;&gt;ServiceComb Java Chassis&lt;/a&gt;框架依赖&lt;/li&gt;
  &lt;li&gt;定义服务接口端点&lt;/li&gt;
  &lt;li&gt;添加服务配置文件&lt;/li&gt;
  &lt;li&gt;注释服务启动入口&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;另外，通过Company Workshop中提供的Docker插件配置，10分钟内完成了服务容器化，自动生成镜像。&lt;/p&gt;

&lt;p&gt;同时，利用ServiceComb开发的微服务应用，可同时无缝接入&lt;a href=&quot;https://www.huaweicloud.com/product/servicestage.html&quot;&gt;ServiceStage&lt;/a&gt;，享受到微服务治理、容器虚机混编、应用拓扑等能力。&lt;/p&gt;

&lt;p&gt;为应对短暂的业务高峰，经常需要预购大量的资源来提前部署和验证环境，花费大量的人力物力，且资源利用率极低。因此，进行云化改造后的产品和解决方案需要具备随着参与人数增加而秒级伸缩，支撑业务峰值和资源利用率的能力。盟拓软件基于华为ServiceStage的核心技术容器改造、混编方案、编排调度算法等进行容器虚机混编应用云化改造，实现了应用的秒级部署和弹性伸缩能力，极大地提高了资源的利用率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;改造后效果：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;运维人力&lt;strong&gt;减少80%&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;资源利用率&lt;strong&gt;提升50%&lt;/strong&gt;，大幅降低运营成本&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;每秒万级&lt;/strong&gt;调用链分析能力&lt;/li&gt;
  &lt;li&gt;传统系统和应用平滑改造上云&lt;/li&gt;
  &lt;li&gt;互联网营销模式，天粒度业务快速创新&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/case_mengtuo_new_mode.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;理论上，经过不断地迭代，逐渐完成业务功能解耦，新服务构建。那么遗留系统就会被替换掉。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;改造要点&quot;&gt;改造要点&lt;/h2&gt;
&lt;p&gt;在改造的整个过程中，我认为如下几个实践是非常重要的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/best_practices_for_legacy_system_reform.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;基础设施自动化&quot;&gt;基础设施自动化&lt;/h3&gt;
&lt;p&gt;原有的部署发生在数据中心，因此流程上相对复杂，而且存在一定弊端（譬如审批和协作上，起不到实质作用）。对于改造后的服务而言，我们使用更多的自动化方式代替复杂的审批流程。通过使用华为ServiceStage作为基础设施，团队能够更自主的对基础设施进行管理。如资源创建、销毁、更新等。随着服务的增多，基础设施自动化帮助我们节省了大量的时间。当然，从组织层面，也成立了专门的小组研究华为ServiceStage以及相关的DevOps配套工具。&lt;/p&gt;

&lt;p&gt;目前，国内外有很多优秀的云平台，可以方便的为用户提供基础设施的自动化机制。&lt;/p&gt;

&lt;h3 id=&quot;微服务生态系统&quot;&gt;微服务生态系统&lt;/h3&gt;
&lt;p&gt;微服务的生态系统是指微服务实施过程相关的协作部分，涉及部分较多，譬如测试机制、持续集成、自动化部署、细粒度监控、日志聚合、告警、持续交付，以及大家非常关注的服务注册、服务发现机制等。&lt;/p&gt;

&lt;p&gt;这部分的灵活性比较大，因为目前如上说的每一个领域都有很多优秀的工具。譬如日志聚合目前业界的方案通常为ELK，监控的方案如Zabbix、NewRelic、CloudWatch等，成熟的监控工具都具有告警功能，PagerDuty也提供更专业的告警服务。服务注册和发现有ServiceComb框架的Service Center，Eureka，Consul，Zookeeper。大家可以在各自的团队中自由发挥。&lt;/p&gt;

&lt;h3 id=&quot;开发框架的演进&quot;&gt;开发框架的演进&lt;/h3&gt;
&lt;p&gt;开发框架是团队在构建微服务的过程中，不断总结，梳理出的快速开发微服务的相关工具和框架。&lt;/p&gt;

&lt;p&gt;我们基于ServiceComb构建了快速开发框架，主要包括四部分，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rapid_development_framework.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;微服务工程示例&lt;/p&gt;

    &lt;p&gt;提供微服务改造架构最佳实践参考工程Company，使能微服务改造或开发能复用其架构设计和配置，同时指导实现服务容器化和后续服务性能测试等提高服务可靠性。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;契约生成工具&lt;/p&gt;

    &lt;p&gt;ServiceComb采用了基于OpenAPI的服务契约，使业务逻辑与编程语言解耦，并可使用Swagger工具定义服务契约，自动生成契约对应的代码和文档。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;持续集成&lt;/p&gt;

    &lt;p&gt;持续集成使用了Jenkins，通过其配置文件定义主要的阶段：&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;验证：运行单元测试，集成测试&lt;/p&gt;

      &lt;p&gt;构建：构建可执行的jar部署包&lt;/p&gt;

      &lt;p&gt;部署：基于指定版本制作镜像，并推送到测试或生产环境下&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;利用这样的持续集成模板工程，花费很少的时间，就可以针对新建的微服务应用，快速配置其对应的持续集成环境。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kubernetes集群一键部署&lt;/p&gt;

    &lt;p&gt;Kubernetes是谷歌开源的一个容器集群管理工具。基于Kubernetes，可实现微服务的快速部署及弹性伸缩。我们提供了一键部署脚本，部署时只需稍作修改即可通过一条命令，自动完成资源的创建、部署、弹性伸缩、金丝雀发布等。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;团队运维自管理&quot;&gt;团队运维自管理&lt;/h3&gt;

&lt;p&gt;这一部分是关于团队的文化管理。也是对DevOPS的延伸，我们称为TMI（Team Managed Infrastructure）。&lt;/p&gt;

&lt;p&gt;目的是将分析、开发、测试以及资源创建、销毁、自动化部署的权利交给团队，由团队按需完成部署（加上看板的流程管理，而非Scrum的固定迭代，可以做到一天部署多次）。&lt;/p&gt;

&lt;p&gt;当然，这个环节非常依赖于成熟的监控以及告警机制，当出现问题时，能够有效的通知到责任人，快速反馈，快速修复。团队内部也会定期轮换Pager（出问题救火的人），培养团队以服务可用作为大家的共同目标，培养产品观念，而非项目观念。&lt;/p&gt;

&lt;p&gt;再回顾一下这个图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/best_practices_for_legacy_system_reform.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后，和大家分享一下，我个人在微服务实施过程中总结的4句方针:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由大到小，由粗到细&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关注运维，关注监控&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;快速反馈，快速修复&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;循序渐进，增量实现&lt;/strong&gt;&lt;/p&gt;</content><author><name>Wang Lei</name><email>wanglei177@huawei.com</email><uri>https://wldandan.github.io</uri></author><category term="Reform legacy system" /><summary type="html">微服务是否是业界期待已久的企业架构解决方案？在对遗留系统进行微服务的改造过程中存在怎样的困难和挑战，应该注意些什么？</summary></entry><entry xml:lang="cn"><title type="html">ServiceComb中的数据最终一致性方案 - part 3</title><link href="/cn/docs/distributed_saga_3/" rel="alternate" type="text/html" title="ServiceComb中的数据最终一致性方案 - part 3" /><published>2017-09-18T00:00:00+08:00</published><updated>2017-09-18T15:22:00+08:00</updated><id>/cn/docs/saga-and-others</id><content type="html" xml:base="/cn/docs/distributed_saga_3/">&lt;p&gt;在我的前一篇&lt;a href=&quot;/cn/docs/distributed_saga_2/&quot;&gt;文章&lt;/a&gt;，我谈到了ServiceComb下的&lt;a href=&quot;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&quot;&gt;Saga&lt;/a&gt;是怎么设计的。
然而，业界还有其他数据一致性解决方案，如两阶段提交（2PC）和Try-Confirm / Cancel（TCC）。那saga相比之下有什么特别？&lt;/p&gt;

&lt;h2 id=&quot;两阶段提交-two-phase-commit-2pc&quot;&gt;两阶段提交 Two-Phase Commit (2PC)&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;两阶段提交协议是一种分布式算法，用于协调参与分布式原子事务的所有进程，以保证他们均完成提交或中止（回滚）事务。&lt;a href=&quot;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&quot;&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2PC包含两个阶段：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;投票阶段&lt;/strong&gt; 协调器向所有服务发起投票请求，服务回答yes或no。如果有任何服务回复no以拒绝或超时，协调器则在下一阶段发送中止消息。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.2pc.phase1.png&quot; alt=&quot;voting phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;决定阶段&lt;/strong&gt; 如果所有服务都回复yes，协调器则向服务发送commit消息，接着服务告知事务完成或失败。如果任何服务提交失败，
协调器将启动额外的步骤以中止该事务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.2pc.phase2.png&quot; alt=&quot;decision phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在投票阶段结束之后与决策阶段结束之前，服务处于&lt;strong&gt;不确定&lt;/strong&gt;状态，因为他们不确定交易是否继续进行。当服务处于不确定状态并与协调器失去连接时，
它只能选择等待协调器的恢复，或者咨询其他在确定状态下的服务来得知协调器的决定。在最坏的情况下，
n个处于不确定状态的服务向其他n-1个服务咨询将产生&lt;strong&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/strong&gt;个消息。&lt;/p&gt;

&lt;p&gt;另外，2PC是一个阻塞协议。服务在投票后需要等待协调器的决定，此时服务会阻塞并锁定资源。由于其阻塞机制和最差时间复杂度高，
2PC不能适应随着事务涉及的服务数量增加而扩展的需要。&lt;/p&gt;

&lt;p&gt;有关2PC实现的更多细节可参考&lt;a href=&quot;https://cs.nyu.edu/courses/spring03/G22.2631-001/lecture8.pdf&quot;&gt;2&lt;/a&gt;和&lt;a href=&quot;http://courses.cs.vt.edu/~cs5204/fall00/distributedDBMS/duckett/tpcp.html&quot;&gt;3&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;try-confirmcancel-tcc&quot;&gt;Try-Confirm/Cancel (TCC)&lt;/h2&gt;
&lt;p&gt;TCC也是补偿型事务模式，支持两阶段的商业模型。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;尝试阶段&lt;/strong&gt; 将服务置于待处理状态。例如，收到尝试请求时，航班预订服务将为客户预留一个座位，并在数据库插入客户预订记录，将记录设为预留状态。
如果任何服务失败或超时，协调器将在下一阶段发送取消请求。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.tcc.try.png&quot; alt=&quot;try phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;确认阶段&lt;/strong&gt; 将服务设为确认状态。确认请求将确认客户预订的座位，这时服务已可向客户收取机票费用。数据库中的客户预订记录也会被更新为确认状态。
如果任何服务无法确认或超时，协调器将重试确认请求直到成功，或在重试了一定次数后采取回退措施，比如人工干预。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.tcc.confirm.png&quot; alt=&quot;confirm phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与saga相比，TCC的优势在于，尝试阶段将服务转为待处理状态而不是最终状态，这使得设计相应的取消操作轻而易举。&lt;/p&gt;

&lt;p&gt;例如，电邮服务的尝试请求可将邮件标记为准备发送，并且仅在确认后发送邮件，其相应的取消请求只需将邮件标记为已废弃。但如果使用saga，
事务将发送电子邮件，及其相应的补偿事务可能需要发送另一封电子邮件作出解释。&lt;/p&gt;

&lt;p&gt;TCC的缺点是其两阶段协议需要设计额外的服务待处理状态，以及额外的接口来处理尝试请求。另外，TCC处理事务请求所花费的时间可能是saga的两倍，
因为TCC需要与每个服务进行两次通信，并且其确认阶段只能在收到所有服务对尝试请求的响应后开始。&lt;/p&gt;

&lt;p&gt;有关TCC的更多细节可参考&lt;a href=&quot;https://www.infoq.com/presentations/Transactions-HTTP-REST&quot;&gt;Transactions for the REST of Us&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;事件驱动的架构&quot;&gt;事件驱动的架构&lt;/h2&gt;
&lt;p&gt;和TCC一样，在事件驱动的架构中，长活事务涉及的每个服务都需要支持额外的待处理状态。接收到事务请求的服务会在其数据库中插入一条新的记录，
将该记录状态设为待处理并发送一个新的事件给事务序列中的下一个服务。&lt;/p&gt;

&lt;p&gt;因为在插入记录后服务可能崩溃，我们无法确定是否新事件已发送，所以每个服务还需要额外的事件表来跟踪当前长活事务处于哪一步。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.event.driven.request.png&quot; alt=&quot;event driven architecture - request&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一旦长活事务中的最后一个服务完成其子事务，它将通知它在事务中的前一个服务。接收到完成事件的服务将其在数据库中的记录状态设为完成。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.event.driven.response.png&quot; alt=&quot;event driven architecture - response&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果仔细比较，事件驱动的架构就像非集中式的基于事件的TCC实现。如果去掉待处理状态而直接把服务记录设为最终状态，这个架构就像非集中式的基于事件的saga实现。
去中心化能达到服务自治，但也造成了服务之间更紧密的的耦合。假设新的业务需求在服务B和C之间的增加了新的流程D。在事件驱动架构下，服务B和C必须改动代码以适应新的流程D。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.event.coupling.png&quot; alt=&quot;event driven architecture - coupling&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Saga则正好相反，所有这些耦合都在saga系统中，当在长活事务中添加新流程时，现有服务不需要任何改动。&lt;/p&gt;

&lt;p&gt;更多细节可参考&lt;a href=&quot;https://www.nginx.com/blog/event-driven-data-management-microservices/&quot;&gt;Event-Driven Data Management for Microservices&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;集中式与非集中式实现&quot;&gt;集中式与非集中式实现&lt;/h2&gt;
&lt;p&gt;这个Saga系列的文章讨论的都是集中式的saga设计。但saga也可用非集中式的方案来实现。那么非集中式的版本有什么不同？&lt;/p&gt;

&lt;p&gt;非集中式saga没有专职的协调器。启动下一个服务调用的服务就是当前的协调器。例如，&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;服务A收到要求服务A，B和C之间的数据一致性的事务请求。&lt;/li&gt;
  &lt;li&gt;A完成其子事务，并将请求传递给事务中的下一个服务，服务B.&lt;/li&gt;
  &lt;li&gt;B完成其子事务，并将请求传递给C，依此类推。&lt;/li&gt;
  &lt;li&gt;如果C处理请求失败，B有责任启动补偿事务，并要求A回滚。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.decentralized.png&quot; alt=&quot;decentralized saga&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与集中式相比，非集中式的实现具有服务自治的优势。但每个服务都需要包含数据一致性协议，并提供其所需的额外持久化设施。&lt;/p&gt;

&lt;p&gt;我们更倾向于自治的业务服务，但服务还关联很多应用的复杂性，如数据一致性，服务监控和消息传递，
将这些棘手问题集中处理，能将业务服务从应用的复杂性中释放，专注于处理复杂的业务，因此我们采用了集中式的saga设计。&lt;/p&gt;

&lt;p&gt;另外，随着长活事务中涉及的服务数量增长，服务之间的关系变得越来越难理解，很快便会呈现下图的死星形状。&lt;/p&gt;

&lt;p class=&quot;figure-caption&quot;&gt;&lt;img src=&quot;/assets/images/saga.death.star.png&quot; alt=&quot;death star architecture&quot; class=&quot;align-center&quot; /&gt;
图片来源: http://www.slideshare.net/BruceWong3/the-case-for-chaos (s12)&lt;/p&gt;

&lt;p&gt;同时，在长活事务中定位问题也变得更加复杂，因为服务日志遍布群集节点。&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;本文将saga与其他数据一致性解决方案进行了比较。Saga比两阶段提交更易扩展。在事务可补偿的情况下，
相比TCC，saga对业务逻辑几乎没有改动的需要，而且性能更高。集中式的saga设计解耦了服务与数据一致性逻辑及其持久化设施，
并使排查事务中的问题更容易。&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&quot;&gt;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.nyu.edu/courses/spring03/G22.2631-001/lecture8.pdf&quot;&gt;https://cs.nyu.edu/courses/spring03/G22.2631-001/lecture8.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://courses.cs.vt.edu/~cs5204/fall00/distributedDBMS/duckett/tpcp.html&quot;&gt;http://courses.cs.vt.edu/~cs5204/fall00/distributedDBMS/duckett/tpcp.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/presentations/Transactions-HTTP-REST&quot;&gt;https://www.infoq.com/presentations/Transactions-HTTP-REST&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/blog/event-driven-data-management-microservices/&quot;&gt;https://www.nginx.com/blog/event-driven-data-management-microservices/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Sean Yin</name><email>seanyinx@gmail.com</email><uri>http://seanyinx.github.io</uri></author><category term="事务一致性" /><summary type="html">Saga和其他数据一致性解决方案相比有什么不同之处？</summary></entry><entry xml:lang="en"><title type="html">Eventual Data Consistency Solution in ServiceComb - part 3</title><link href="/docs/distributed_saga_3/" rel="alternate" type="text/html" title="Eventual Data Consistency Solution in ServiceComb - part 3" /><published>2017-09-18T00:00:00+08:00</published><updated>2017-09-18T15:22:00+08:00</updated><id>/docs/saga-and-others</id><content type="html" xml:base="/docs/distributed_saga_3/">&lt;p&gt;In my &lt;a href=&quot;/docs/distributed_saga_2/&quot;&gt;previous post&lt;/a&gt;, I talked about how &lt;a href=&quot;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&quot;&gt;Saga&lt;/a&gt; in
ServiceComb is designed. However, there are quite a few data consistency solutions such as Two-Phase Commit (2PC) 
and Try-Confirm/Cancel (TCC). What makes saga special?&lt;/p&gt;

&lt;h2 id=&quot;two-phase-commit-2pc&quot;&gt;Two-Phase Commit (2PC)&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Two-phase commit protocol is a distributed algorithm that coordinates all the processes that participate in a distributed 
atomic transaction on whether to commit or abort (roll back) the transaction. &lt;a href=&quot;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&quot;&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It has two phases:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;voting phase&lt;/strong&gt; coordinator sends vote request to all services and services respond with either yes or no. If any service
refuse with no or timeout, coordinator sends abort message in the next phase.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.2pc.phase1.png&quot; alt=&quot;voting phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;decision phase&lt;/strong&gt; if all services say yes, coordinator sends commit message to services and services acknowledge either
transaction done or failed. If any service fails to commit, coordinator will initiate additional rounds to abort the transaction.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.2pc.phase2.png&quot; alt=&quot;decision phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Between the end of voting phase and the end of decision phase, services are in &lt;strong&gt;uncertain&lt;/strong&gt; state, because they are not sure
if the transaction is going to proceed or not. When a service is in uncertain state and loses connection with coordinator,
it may either wait for coordinator's recovery, or consult other services in certain state for coordinator's decision.
In the worst case, n uncertain services broadcasting messages to other n - 1 services will incur &lt;strong&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/strong&gt; messages.&lt;/p&gt;

&lt;p&gt;Another disadvantage of 2PC is that it is a blocking protocol. A service will block and lock resources, while waiting for
decision from coordinator after voting. 2PC does not scale well when the number of services involved in a transaction grows,
because of its blocking mechanism and worst case time complexity.&lt;/p&gt;

&lt;p&gt;More details on implementation of 2PC can be found at &lt;a href=&quot;https://cs.nyu.edu/courses/spring03/G22.2631-001/lecture8.pdf&quot;&gt;2&lt;/a&gt; and &lt;a href=&quot;http://courses.cs.vt.edu/~cs5204/fall00/distributedDBMS/duckett/tpcp.html&quot;&gt;3&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;try-confirmcancel-tcc&quot;&gt;Try-Confirm/Cancel (TCC)&lt;/h2&gt;
&lt;p&gt;TCC is a compensating transaction pattern for business model that is two-phased.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;try phase&lt;/strong&gt; puts a service in pending state. For example, a try request in our flight booking service will reserve a
seat for the customer and insert a customer reservation record with reserved state into database. If any service fails to
make a reservation or times out, the coordinator will send a cancel request in the next phase.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.tcc.try.png&quot; alt=&quot;try phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;confirm phase&lt;/strong&gt; moves the service to confirmed state. A confirm request will confirm that a seat is booked for the 
customer and he or she will be billed. The customer reservation record in database will be updated to confirmed state.
If any service fails to confirm or times out, the coordinator will either retry confirmation until success or involve manual
intervention after it retries a certain number of times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.tcc.confirm.png&quot; alt=&quot;confirm phase&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Comparing with saga, TCC has an advantage in that try phase transitions services into pending state instead of final
state, which makes cancellation trivial to design.&lt;/p&gt;

&lt;p&gt;For example, a try request for an email service may mark an email as ready to send and the email is only sent on confirm 
request. Its corresponding cancel request needs only to mark the email as obsolete. However, in case of using saga, a transaction
will send the email and its corresponding compensating transaction may have to send another email to explain the problem.&lt;/p&gt;

&lt;p&gt;The disadvantage of TCC, comparing with saga, is that its two-phased protocol requires services to be designed with additional
pending state and interface to handle try request. And it may take twice the time to complete a TCC request than a saga request,
because TCC communicates with each service twice and the confirm phase can only be started when responses of try request
are received from all services.&lt;/p&gt;

&lt;p&gt;More detailed explanation of TCC can be found at &lt;a href=&quot;https://www.infoq.com/presentations/Transactions-HTTP-REST&quot;&gt;Transactions for the REST of Us&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;event-driven-architecture&quot;&gt;Event Driven Architecture&lt;/h2&gt;
&lt;p&gt;In event driven architecture, just like TCC, an extra pending status is required for each service involved in a long live transaction.
Services receiving transaction request insert a new record into its database with pending status and send a new event to
the next service in the transaction sequence.&lt;/p&gt;

&lt;p&gt;Because it's possible that a service crashes after inserting the record and we are not sure if the new event is sent,
an extra event table is required for each service to keep track of which step the current long live transaction is in.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.event.driven.request.png&quot; alt=&quot;event driven architecture - request&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once the last service in the long live transaction completes its job, it notifies the previous service in the transaction.
Services receiving completion event set its record status to done in its database.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.event.driven.response.png&quot; alt=&quot;event driven architecture - response&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you look closer, event driven architecture is just like a decentralized implementation of event driven TCC. If we remove
the pending state for each service, this architecture looks like a decentralized and event driven saga.
Being decentralized is good, but it creates much tighter coupling between services. Let's assume a new business requirement adds a new
process D between B and C. With event driven architecture, service B and C have to change their code to accommodate the new 
process D.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.event.coupling.png&quot; alt=&quot;event driven architecture - coupling&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the contrary, all these coupling is in saga and no change is required for existing services when a new process is added
to the long live transaction.&lt;/p&gt;

&lt;p&gt;More details can be found at &lt;a href=&quot;https://www.nginx.com/blog/event-driven-data-management-microservices/&quot;&gt;Event-Driven Data Management for Microservices&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;centralized-vs-decentralized&quot;&gt;Centralized vs Decentralized&lt;/h2&gt;
&lt;p&gt;This blog series have been talked about centralized saga. But saga can be implemented as decentralized solution too. 
How does the decentralized version look like?&lt;/p&gt;

&lt;p&gt;The decentralized version of saga does not have a dedicated coordinator. Whoever calling the next service
in the transaction becomes the current coordinator instead. For example,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;service A receives a request requiring data consistency across service A, B, and C.&lt;/li&gt;
  &lt;li&gt;A does its job and passes the request to the next service in the request, service B.&lt;/li&gt;
  &lt;li&gt;B completes its part and passes the request to C, and so on.&lt;/li&gt;
  &lt;li&gt;If C fails to process the request, it is B's responsibility to initiate its compensating transaction and asks A to rollback.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.decentralized.png&quot; alt=&quot;decentralized saga&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Comparing with centralized one, the decentralized version has the advantage of service autonomy. But each service is
coupled with data consistency protocol, which may require additional persistence infrastructure.&lt;/p&gt;

&lt;p&gt;We love services implementing business rules to be autonomous, but there are many application related complexity such as
data consistency, service monitoring, and message passing, that are better to be centralized, so that business services
are able to focus on dealing with business complexity instead of application complexity. That's why we designed centralized saga.&lt;/p&gt;

&lt;p&gt;In addition, the relationship among services in a long live transaction becomes harder and harder to understand, as the 
number of services grows. It may quickly grow into a death star like the image below.&lt;/p&gt;

&lt;p class=&quot;figure-caption&quot;&gt;&lt;img src=&quot;/assets/images/saga.death.star.png&quot; alt=&quot;death star architecture&quot; class=&quot;align-center&quot; /&gt;
Image source: http://www.slideshare.net/BruceWong3/the-case-for-chaos (s12)&lt;/p&gt;

&lt;p&gt;Meanwhile, locating the root cause of a problem in a long live transaction also becomes more troublesome, since the 
service logs are spread all over cluster nodes.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In this article, we compared saga with other data consistency solutions. Saga is more scalable than two-phase commit and
is preferable to TCC in scenarios where compensating transactions are feasible and minimal changes to business logic is
required. Centralized saga decouples services from data consistency logic and its persistence infrastructure
and allows easier troubleshooting of any problem occurred in transactions.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&quot;&gt;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.nyu.edu/courses/spring03/G22.2631-001/lecture8.pdf&quot;&gt;https://cs.nyu.edu/courses/spring03/G22.2631-001/lecture8.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://courses.cs.vt.edu/~cs5204/fall00/distributedDBMS/duckett/tpcp.html&quot;&gt;http://courses.cs.vt.edu/~cs5204/fall00/distributedDBMS/duckett/tpcp.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/presentations/Transactions-HTTP-REST&quot;&gt;https://www.infoq.com/presentations/Transactions-HTTP-REST&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/blog/event-driven-data-management-microservices/&quot;&gt;https://www.nginx.com/blog/event-driven-data-management-microservices/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Sean Yin</name><email>seanyinx@gmail.com</email><uri>http://seanyinx.github.io</uri></author><category term="saga" /><summary type="html">How is distributed saga in ServiceComb comparing with other consistency solutions?</summary></entry><entry xml:lang="cn"><title type="html">ServiceComb中的数据最终一致性方案 - part 2</title><link href="/cn/docs/distributed_saga_2/" rel="alternate" type="text/html" title="ServiceComb中的数据最终一致性方案 - part 2" /><published>2017-09-16T00:00:00+08:00</published><updated>2017-09-16T19:05:00+08:00</updated><id>/cn/docs/saga-design</id><content type="html" xml:base="/cn/docs/distributed_saga_2/">&lt;p&gt;在我的前一篇&lt;a href=&quot;/cn/docs/distributed_saga_1/&quot;&gt;文章&lt;/a&gt;，我谈到怎么用&lt;a href=&quot;https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf&quot;&gt;Saga&lt;/a&gt;解决行程规划应用的数据一致性问题。
现在让我们尝试设计实现Saga。&lt;/p&gt;

&lt;h2 id=&quot;saga-log&quot;&gt;Saga Log&lt;/h2&gt;
&lt;p&gt;Saga保证所有的子事务都得以完成或补偿，但Saga系统本身也可能会崩溃。Saga崩溃时可能处于以下几个状态：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Saga收到事务请求，但尚未开始。因子事务对应的微服务状态未被Saga修改，我们什么也不需要做。&lt;/li&gt;
  &lt;li&gt;一些子事务已经完成。重启后，Saga必须接着上次完成的事务恢复。&lt;/li&gt;
  &lt;li&gt;子事务已开始，但尚未完成。由于远程服务可能已完成事务，也可能事务失败，甚至服务请求超时，saga只能重新发起之前未确认完成的子事务。这意味着子事务必须幂等。&lt;/li&gt;
  &lt;li&gt;子事务失败，其补偿事务尚未开始。Saga必须在重启后执行对应补偿事务。&lt;/li&gt;
  &lt;li&gt;补偿事务已开始但尚未完成。解决方案与上一个相同。这意味着补偿事务也必须是幂等的。&lt;/li&gt;
  &lt;li&gt;所有子事务或补偿事务均已完成，与第一种情况相同。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了恢复到上述状态，我们必须追踪子事务及补偿事务的每一步。我们决定通过事件的方式达到以上要求，并将以下事件保存在名为saga log的持久存储中：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Saga started event&lt;/strong&gt; 保存整个saga请求，其中包括多个事务/补偿请求&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction started event&lt;/strong&gt; 保存对应事务请求&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction ended event&lt;/strong&gt; 保存对应事务请求及其回复&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction aborted event&lt;/strong&gt; 保存对应事务请求和失败的原因&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transaction compensated event&lt;/strong&gt; 保存对应补偿请求及其回复&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Saga ended event&lt;/strong&gt; 标志着saga事务请求的结束，不需要保存任何内容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.events.png&quot; alt=&quot;Events&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过将这些事件持久化在saga log中，我们可以将saga恢复到上述任何状态。&lt;/p&gt;

&lt;p&gt;由于Saga只需要做事件的持久化，而事件内容以JSON的形式存储，Saga log的实现非常灵活，数据库（SQL或NoSQL），持久消息队列，甚至普通文件可以用作事件存储，
当然有些能更快得帮saga恢复状态。&lt;/p&gt;

&lt;h2 id=&quot;saga请求的数据结构&quot;&gt;Saga请求的数据结构&lt;/h2&gt;
&lt;p&gt;在我们的业务场景下，航班预订、租车、和酒店预订没有依赖关系，可以并行处理，但对于我们的客户来说，只在所有预订成功后一次付费更加友好。
那么这四个服务的事务关系可以用下图表示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.transactions.png&quot; alt=&quot;Transactions&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将行程规划请求的数据结构实现为&lt;a href=&quot;https://en.wikipedia.org/wiki/Directed_acyclic_graph&quot;&gt;有向非循环图&lt;/a&gt;恰好合适。
图的根是saga启动任务，叶是saga结束任务。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.graph.png&quot; alt=&quot;Request Graph&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;parallel-saga&quot;&gt;Parallel Saga&lt;/h2&gt;
&lt;p&gt;如上所述，航班预订，租车和酒店预订可以并行处理。但是这样做会造成另一个问题：如果航班预订失败，而租车正在处理怎么办？我们不能一直等待租车服务回应，
因为不知道需要等多久。&lt;/p&gt;

&lt;p&gt;最好的办法是再次发送租车请求，获得回应，以便我们能够继续补偿操作。但如果租车服务永不回应，我们可能需要采取回退措施，比如手动干预。&lt;/p&gt;

&lt;p&gt;超时的预订请求可能最后仍被租车服务收到，这时服务已经处理了相同的预订和取消请求。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.commutative.png&quot; alt=&quot;Network Latency&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此，服务的实现必须保证补偿请求执行以后，再次收到的对应事务请求无效。
Caitie McCaffrey在她的演讲&lt;a href=&quot;https://www.youtube.com/watch?v=1H6tounpnG8&quot;&gt;Distributed Sagas: A Protocol for Coordinating Microservices&lt;/a&gt;中把这个称为&lt;strong&gt;可交换的补偿请求 (commutative compensating request)&lt;/strong&gt; 。&lt;/p&gt;

&lt;h2 id=&quot;acid-and-saga&quot;&gt;ACID and Saga&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/ACID&quot;&gt;ACID&lt;/a&gt;是具有以下属性的一致性模型:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;原子性（Atomicity）&lt;/li&gt;
  &lt;li&gt;一致性（Consistency）&lt;/li&gt;
  &lt;li&gt;隔离性（Isolation）&lt;/li&gt;
  &lt;li&gt;持久性（Durability）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Saga不提供ACID保证，因为原子性和隔离性不能得到满足。原&lt;a href=&quot;https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf&quot;&gt;论文&lt;/a&gt;描述如下：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;full atomicity is not provided. That is, sagas may view the partial results of other sagas [&lt;a href=&quot;https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf&quot;&gt;1&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过saga log，saga可以保证一致性和持久性。&lt;/p&gt;

&lt;h2 id=&quot;saga-架构&quot;&gt;Saga 架构&lt;/h2&gt;
&lt;p&gt;最后，我们的Saga架构如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/saga.design.png&quot; alt=&quot;Saga Architecture&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Saga Execution Component解析请求JSON并构建请求图&lt;/li&gt;
  &lt;li&gt;TaskRunner 用任务队列确保请求的执行顺序&lt;/li&gt;
  &lt;li&gt;TaskConsumer 处理Saga任务，将事件写入saga log，并将请求发送到远程服务&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文讨论了如何实现saga，通过saga log来保存事务和补偿事件。也提到如何从saga log中持久化的事件恢复崩溃的saga系统。
为了满足saga的一致性保证，微服务的设计有以下几个要求：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;事务和赔偿请求必须幂等&lt;/li&gt;
  &lt;li&gt;补偿请求必须可交换（commutative）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf&quot;&gt;Original Paper on Sagas&lt;/a&gt; by By Hector Garcia-Molina &amp;amp; Kenneth Salem&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Sean Yin</name><email>seanyinx@gmail.com</email><uri>http://seanyinx.github.io</uri></author><category term="事务一致性" /><summary type="html">ServiceComb中的分布式Saga设计</summary></entry></feed>